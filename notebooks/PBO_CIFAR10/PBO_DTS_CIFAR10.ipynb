{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preferential Bayesian Optimization: Dueling-Thompson Sampling\n",
    "\n",
    "Implementation of the algorithm by Gonzalez et al (2017).\n",
    "\n",
    "Over the CIFAR-10 dataset, we define an arbitrary preference as such (with class number in parentheses):\n",
    "\n",
    "Airplane (0) > Automobile (1) > Ship (8) > Truck (9) > Bird (2) > Cat (3) > Deer (4) > Dog (5) > Frog (6) > Horse (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "from gpflow.utilities import set_trainable, print_summary\n",
    "gpflow.config.set_default_summary_fmt(\"notebook\")\n",
    "\n",
    "sys.path.append(os.path.split(os.path.split(os.path.split(os.getcwd())[0])[0])[0]) # Move 3 levels up directory to import PBO\n",
    "import PBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_to_use = 0\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_visible_devices(gpus[gpu_to_use], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(message):\n",
    "    print(str(datetime.datetime.now()) + ': ' + message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_embedding = pickle.load( open( \"cifar_embedding_reduced.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_to_class = pickle.load( open( \"embedding_to_class_reduced.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = lambda x: PBO.objectives.cifar(x, embedding_to_class)\n",
    "objective_low = np.min(cifar_embedding)\n",
    "objective_high = np.max(cifar_embedding)\n",
    "objective_name = \"CIFAR\"\n",
    "acquisition_name = \"DTS\"\n",
    "experiment_name = \"PBO\" + \"_\" + acquisition_name + \"_\" + objective_name + \"_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(x):\n",
    "    \"\"\"\n",
    "    :param x: tensor of shape (..., 2). CIFAR-10 embeddings\n",
    "    :return: tensor of shape (..., 1). last dim is int from 0-9 representing class\n",
    "    \"\"\"\n",
    "    shape = x.shape[:-1]\n",
    "    raveled = np.reshape(x, [-1, 2])\n",
    "    raveled_shape = raveled.shape[:-1]\n",
    "    raveled_classes = np.zeros((raveled_shape[0], 1), dtype=np.int8)\n",
    "    \n",
    "    for i in range(raveled_shape[0]):\n",
    "        raveled_classes[i] = embedding_to_class[raveled[i].data.tobytes()]\n",
    "        \n",
    "    return np.reshape(raveled_classes, shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer_lengthscale_mean_over_range = 0.2\n",
    "regularizer_lengthscale_std_over_range = 0.5\n",
    "input_range = objective_high - objective_low\n",
    "lengthscale_mean_regularizer = input_range * regularizer_lengthscale_mean_over_range\n",
    "lengthscale_std_regularizer = input_range * regularizer_lengthscale_std_over_range\n",
    "lengthscale = lengthscale_mean_regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 8\n",
    "num_evals = 35\n",
    "num_choices = 2\n",
    "input_dims = 2\n",
    "objective_dim = input_dims\n",
    "num_init_prefs = 6\n",
    "num_fourier_features = 200\n",
    "num_in_subset = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = os.getcwd() + '/results/' + experiment_name + '/'\n",
    "\n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.makedirs(results_dir)\n",
    "    print(\"Directory \" , results_dir ,  \" created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , results_dir ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_representation(X, num_choices):\n",
    "    \"\"\"\n",
    "    :param X: tensor of shape (num_data, input_dims * num_choices)\n",
    "    :return: tensor of shape (num_data, num_choices, input_dims)\n",
    "    \"\"\"\n",
    "    input_dims = X.shape[-1] // num_choices\n",
    "    ret_val = np.zeros((X.shape[0], num_choices, input_dims))\n",
    "    \n",
    "    for i in range(num_choices):\n",
    "        ret_val[:, i, :] = X[:, input_dims*i:input_dims*(i+1)]\n",
    "        \n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noisy_observation_dts(X, objective):\n",
    "    \"\"\"\n",
    "    :param X: tensor of shape (num_data, input_dims * 2)\n",
    "    :param objective: objective function\n",
    "    \"\"\"\n",
    "    num_data = X.shape[0]\n",
    "    X_std = std_representation(X, num_choices) # (num_data, num_choices, input_dims)\n",
    "    f = PBO.objectives.objective_get_f_neg(X_std, objective)\n",
    "    obs = np.array(PBO.observation_model.gen_observation_from_f(X_std, f, 1))  # (num_data, 1, input_dims)\n",
    "\n",
    "    ret_val = np.zeros((num_data, 1), dtype=np.int8)\n",
    "    for i in range(num_data):\n",
    "        if np.allclose(X_std[i, 0], obs[i, 0]):\n",
    "            ret_val[i] = 1\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def lengthscale_regularizer(kernel):  # for product kernel\n",
    "    loss = 0\n",
    "    for k in kernel.kernels:\n",
    "        loss += 0.5 * tf.reduce_sum(tf.square((k.lengthscale - lengthscale_mean_regularizer) / lengthscale_std_regularizer))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_visualize(X, y, lengthscale, title, num_steps=3000):\n",
    "    kernel = gpflow.kernels.Product([gpflow.kernels.RBF(lengthscale=lengthscale, \n",
    "                                                        active_dims=[i, i+input_dims]) \n",
    "                                     for i in range(input_dims)])\n",
    "    \n",
    "    m = gpflow.models.SVGP(kernel=kernel,\n",
    "                           likelihood=gpflow.likelihoods.Bernoulli(invlink=tf.math.sigmoid),\n",
    "                           inducing_variable=X,\n",
    "                           whiten=False)\n",
    "    \n",
    "    m.inducing_variable.Z.trainable = False\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.RMSprop(rho=0.0)\n",
    "    \n",
    "    loss = lambda: -m.log_likelihood(X, y) + lengthscale_regularizer(m.kernel)\n",
    "    prev_loss = loss().numpy()\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        optimizer.minimize(loss, m.trainable_variables)\n",
    "        current_loss = loss().numpy()\n",
    "        if i % 500 == 0:\n",
    "            print('Loss at step %s: %s' % (i, current_loss))\n",
    "        if abs((current_loss-prev_loss) / prev_loss) < 1e-7:\n",
    "            print('Loss at step %s: %s' % (i, current_loss))\n",
    "            break\n",
    "        prev_loss = current_loss\n",
    "        \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pref_inversions(model):\n",
    "    \"\"\"\n",
    "    Method to evaluate models over discrete preference rankings. Given an objective preference ranking over classes, \n",
    "    we calculate the average mean the model assigns to each class, sort the classes according to this average mean,\n",
    "    then calculate the number of inversions required to reach the desired objective preference ranking. 0 inversions\n",
    "    means the model has learned the preference ranking perfectly. The more inversions, the further away the model is.\n",
    "    \"\"\"\n",
    "    def count_inversions(input_list):\n",
    "        def swap(lst, i, j):\n",
    "            tmp = lst[j]\n",
    "            lst[j] = lst[i]\n",
    "            lst[i] = tmp\n",
    "\n",
    "        lst = input_list.copy()\n",
    "        num_inversions = 0\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            for i in range(len(lst) - 1):\n",
    "                if lst[i] > lst[i+1]:\n",
    "                    swap(lst, i, i+1)\n",
    "                    num_inversions += 1\n",
    "                    changed = True\n",
    "                    \n",
    "        return num_inversions\n",
    "    \n",
    "    \n",
    "    class_to_posval = {0: -0.1,\n",
    "                     1: -0.2,\n",
    "                     8: -0.3,\n",
    "                     9: -0.4,\n",
    "                     2: -0.5,\n",
    "                     3: -0.6,\n",
    "                     4: -0.7,\n",
    "                     5: -0.8,\n",
    "                     6: -0.9,\n",
    "                     7: -1.}  # higher is more preferred here\n",
    "    \n",
    "    fvals = model.predict_y(cifar_embedding)[0]\n",
    "    indices = get_class(cifar_embedding)\n",
    "    \n",
    "    average_f = tf.scatter_nd(indices=indices,\n",
    "                   updates=np.squeeze(fvals),\n",
    "                   shape=tf.constant([10]))/5000\n",
    "    sorted_f = sorted(list(zip(average_f, range(10))))\n",
    "    \n",
    "    model_posvals = []\n",
    "    for pair in sorted_f:\n",
    "        model_posvals.append(class_to_posval[pair[1]])\n",
    "        \n",
    "    return count_inversions(model_posvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maximizing_class(model):\n",
    "    fvals = model.predict_y(cifar_embedding)[0]\n",
    "    indices = get_class(cifar_embedding)\n",
    "    \n",
    "    average_f = tf.scatter_nd(indices=indices,\n",
    "                   updates=np.squeeze(fvals),\n",
    "                   shape=tf.constant([10]))/5000\n",
    "    sorted_f = sorted(list(zip(average_f, range(10))))\n",
    "    return sorted_f[9][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(X):\n",
    "    \"\"\"\n",
    "    :param X: tensor of shape (num_data, input_dims * 2)\n",
    "    :return: tensor of shape (num_data, input_dims * 2), where the first input_dims is swapped with the second\n",
    "    \"\"\"\n",
    "    input_dims = X.shape[-1] // 2\n",
    "    ret_val = np.zeros((X.shape))\n",
    "    for i in range(X.shape[0]):\n",
    "        ret_val[i, :input_dims] = X[i, input_dims:]\n",
    "        ret_val[i, input_dims:] = X[i, :input_dims]\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_y(y):\n",
    "    \"\"\"\n",
    "    :param y: tensor of shape (num_data, 1), with int values either 0 or 1\n",
    "    \"\"\"\n",
    "    return (y + 1) % 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the initial values for each run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random_indices = np.random.choice(cifar_embedding.shape[0], [num_runs, num_init_prefs, num_choices], replace=False)\n",
    "init_vals = np.take(cifar_embedding, random_indices, axis=0)\n",
    "init_vals = np.reshape(init_vals, (num_runs, num_init_prefs, num_choices * input_dims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the results in these arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_at_end = (num_init_prefs + num_evals) * 2\n",
    "X_results = np.zeros([num_runs, num_data_at_end, input_dims * num_choices])\n",
    "y_results = np.zeros([num_runs, num_data_at_end, 1])\n",
    "inversion_results = np.zeros([num_runs, num_evals], np.int32)\n",
    "max_class_results = np.zeros([num_runs, num_evals], np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in range(num_runs):\n",
    "    log(\"Starting run {}\".format(run))\n",
    "    #Fit a GP with kernel k to Dn\n",
    "    \n",
    "    X = init_vals[run]\n",
    "    y = get_noisy_observation_dts(X, objective)\n",
    "    \n",
    "    X = np.vstack([X, flip(X)])\n",
    "    y = np.vstack([y, flip_y(y)])\n",
    "    \n",
    "    model = train_and_visualize(X, y, lengthscale=lengthscale, title=\"Run_{}_Initial_model\".format(run))\n",
    "    \n",
    "    for evaluation in range(num_evals):\n",
    "        log(\"Starting evaluation \" + str(evaluation))\n",
    "        \n",
    "\n",
    "        \n",
    "        is_valid_query = False\n",
    "        num_tries = 0\n",
    "        while not is_valid_query:\n",
    "            # Get random subset of cifar_embedding to use per evaluation\n",
    "            subset_indices = np.random.choice(cifar_embedding.shape[0], num_in_subset, replace=False)\n",
    "            discrete_space = np.take(cifar_embedding, subset_indices, axis=0)\n",
    "            combs = PBO.acquisitions.dts.combinations(discrete_space)\n",
    "            \n",
    "            # Sample f using RFF\n",
    "            f_vals = PBO.acquisitions.dts.sample_f(model, X, combs, num_fourier_features)\n",
    "\n",
    "            # 2 and 3. Compute the acquisition for duels alpha and get next duel\n",
    "            log(\"Computing acquisition function\")\n",
    "            x_next = PBO.acquisitions.dts.soft_copeland_maximizer(f_vals, discrete_space)        \n",
    "\n",
    "            all_pairs = np.concatenate([np.tile(x_next, (discrete_space.shape[0], 1)), discrete_space], axis=1)\n",
    "            next_vars = np.squeeze(PBO.acquisitions.dts.variance_logistic_f(model, all_pairs), \n",
    "                                   axis=1)\n",
    "            xprime_next = discrete_space[np.argmax(next_vars)]\n",
    "\n",
    "            x_xprime_next = np.expand_dims(np.concatenate([x_next, xprime_next]), axis=0)\n",
    "\n",
    "            # If both x and x' are equal, or the query has already been made, will cause Fourier features matrix\n",
    "            # to become non-invertible later on\n",
    "            if np.all(np.equal(x_xprime_next, flip(x_xprime_next))) or x_xprime_next in X:\n",
    "                log(\"Invalid query, resampling f\")\n",
    "                num_tries += 1\n",
    "                if num_tries >= 100:\n",
    "                    raise ValueError\n",
    "            else:\n",
    "                log(\"x and x_prime: \\n\" + str(x_xprime_next))\n",
    "                is_valid_query = True\n",
    "        \n",
    "        # 4. Run the duel and get y\n",
    "        y_next = get_noisy_observation_dts(x_xprime_next, objective)\n",
    "        log(\"y_next: \\n\" + str(y_next))\n",
    "        \n",
    "        # 5. Augment X and Y, and add symmetric points\n",
    "        X = np.vstack([X, x_xprime_next, flip(x_xprime_next)])\n",
    "        y = np.vstack([y, y_next, flip_y(y_next)])\n",
    "        \n",
    "        # Fit a GP with kernel k to Dj and learn pi(x).\n",
    "        model = train_and_visualize(X, y, lengthscale=lengthscale, title=\"Run_{}_Evaluation_{}\".format(run, evaluation))\n",
    "        \n",
    "        # Save model\n",
    "        kernels_variance = []\n",
    "        kernels_lengthscale = []\n",
    "        for k in model.kernel.kernels:\n",
    "            kernels_variance.append(k.variance.numpy())\n",
    "            kernels_lengthscale.append(k.lengthscale.numpy())\n",
    "\n",
    "        pickle.dump((X, y, \n",
    "                    tuple(kernels_variance),\n",
    "                    tuple(kernels_lengthscale),\n",
    "                    model.q_mu.numpy(),\n",
    "                    model.q_sqrt.numpy()), \n",
    "                 open(results_dir + \"Model_Run_{}_Evaluation_{}.p\".format(run, evaluation), \"wb\"))\n",
    "        \n",
    "        inversion_results[run, evaluation] = pref_inversions(model)\n",
    "        max_class_results[run, evaluation] = get_maximizing_class(model)\n",
    "        \n",
    "        print(\"Inversions: {}, maximizing class: {}\".format(inversion_results[run, evaluation], \n",
    "                                                           max_class_results[run, evaluation]))\n",
    "\n",
    "    X_results[run] = X\n",
    "    y_results[run] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pickle.dump((X_results, y_results, inversion_results, max_class_results), open(results_dir + \"Xybestguess.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
