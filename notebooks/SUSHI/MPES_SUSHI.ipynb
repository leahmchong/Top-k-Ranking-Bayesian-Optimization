{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preferential Bayesian Optimization: Multinomial Predictive Entropy Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from gpflow.utilities import set_trainable, print_summary\n",
    "gpflow.config.set_default_summary_fmt(\"notebook\")\n",
    "\n",
    "sys.path.append(os.path.split(os.path.split(os.path.split(os.getcwd())[0])[0])[0]) # Move 3 levels up directory to import PBO\n",
    "import PBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  4\n",
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpu_to_use = 2\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_visible_devices(gpus[gpu_to_use], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = pickle.load( open( \"sushi_features.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fvals = pickle.load( open( \"fvals.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct dict\n",
    "feat_to_fval_dict = {}\n",
    "for i in range(len(features)):\n",
    "    key = features[i].data.tobytes()\n",
    "    feat_to_fval_dict[key] = fvals[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = lambda x: PBO.objectives.sushi(x, feat_to_fval_dict)\n",
    "objective_low = np.min(features)\n",
    "objective_high = np.max(features)\n",
    "objective_name = \"SUSHI\"\n",
    "acquisition_name = \"MPES\"\n",
    "experiment_name = \"PBO\" + \"_\" + acquisition_name + \"_\" + objective_name + \"_\" + \"v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 10\n",
    "num_evals = 35\n",
    "num_choices = 2\n",
    "input_dims = 6\n",
    "num_maximizers = 20\n",
    "num_maximizers_init = 50\n",
    "num_fourier_features = 1000\n",
    "num_init_prefs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  /temp/sebtaysh/PBO/notebooks/SUSHI/results/PBO_MPES_SUSHI_v1/  created \n"
     ]
    }
   ],
   "source": [
    "results_dir = os.getcwd() + '/results/' + experiment_name + '/'\n",
    "\n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.makedirs(results_dir)\n",
    "    print(\"Directory \" , results_dir ,  \" created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , results_dir ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noisy_observation(X, objective):\n",
    "    f = PBO.objectives.objective_get_f_neg(X, objective)\n",
    "    return PBO.observation_model.gen_observation_from_f(X, f, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_visualize(X, y, title, lengthscale_init=None, signal_variance_init=None):\n",
    "    \n",
    "    # Train model with data\n",
    "    result = PBO.models.learning_fullgp.train_model_fullcov(\n",
    "                        X, y, \n",
    "                        obj_low=objective_low,\n",
    "                        obj_high=objective_high,\n",
    "                        lengthscale_init=lengthscale_init,\n",
    "                        signal_variance_init=signal_variance_init,\n",
    "                        indifference_threshold=0.,\n",
    "                        n_sample=1000,\n",
    "                        deterministic=True, # only sample f values once, not re-sampling\n",
    "                        num_steps=3000)\n",
    "    \n",
    "    q_mu = result['q_mu']\n",
    "    q_sqrt = result['q_sqrt']\n",
    "    u = result['u']\n",
    "    inputs = result['inputs']\n",
    "    k = result['kernel']\n",
    "    \n",
    "    likelihood = gpflow.likelihoods.Gaussian()\n",
    "    model = PBO.models.learning.init_SVGP_fullcov(q_mu, q_sqrt, u, k, likelihood)\n",
    "    u_mean = q_mu.numpy()\n",
    "    inducing_vars = u.numpy()\n",
    "    \n",
    "    return model, inputs, u_mean, inducing_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate rank dictionary and immediate regret dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fval_idx_tuples = pickle.load(open(\"fval_idx_tuples.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_dict = {}\n",
    "\n",
    "for i in range(len(fval_idx_tuples)):\n",
    "    rank_dict[features[fval_idx_tuples[i][1]].data.tobytes()] = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is our main metric for the performance of the acquisition function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_sushi(model, features, rank_dict):\n",
    "    \"\"\"\n",
    "    :param model: gpflow model\n",
    "    :param features: sushi features\n",
    "    :param rank_dict: dictionary from sushi idx to place in ranking\n",
    "    :return: tuple (index of max sushi, rank)\n",
    "    \"\"\"\n",
    "    f_preds = model.predict_f(features)[0]\n",
    "    max_idx = np.argmax(f_preds)\n",
    "    \n",
    "    return (max_idx, rank_dict[features[max_idx].data.tobytes()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the results in these arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_at_end = int(num_init_prefs + num_evals)\n",
    "X_results = np.zeros([num_runs, num_data_at_end, num_choices, input_dims])\n",
    "y_results = np.zeros([num_runs, num_data_at_end, 1, input_dims])\n",
    "immediate_regret = np.zeros([num_runs, num_evals], np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the initial values for each run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random_indices = np.random.choice(features.shape[0], [num_runs, num_init_prefs, num_choices])\n",
    "init_vals = np.take(features, random_indices, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loops carry out the Bayesian optimization algorithm over a number of runs, with a fixed number of evaluations per run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning run 0\n",
      "Optimizer config:  {'name': 'RMSprop', 'learning_rate': 0.001, 'decay': 0.0, 'rho': 0.0, 'momentum': 0.0, 'epsilon': 1e-07, 'centered': False}\n",
      "Indifference_threshold is fixed at 0.0\n",
      "Initialize lengthscale at [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "       signal variance at 1.0\n",
      "   Initial negative ELBO: 262.84744756425255\n",
      "Negative ELBO at step 0: 260.5604772808247 in 3.2332s\n",
      "Negative ELBO at step 500: 13.630805260974794 in 53.2371s\n",
      "Negative ELBO at step 1000: 12.2780915953055 in 53.1633s\n",
      "Negative ELBO at step 1500: 11.987157070250117 in 55.3429s\n",
      "Negative ELBO at step 2000: 11.84868908043159 in 54.3034s\n",
      "Negative ELBO at step 2500: 11.762156281424161 in 52.8458s\n",
      "Beginning evaluation 0\n",
      "Evaluation 0: Sampling maximizers\n",
      "Loss at step 0: -0.06518032343464204\n",
      "Loss at step 500: -1.9894941611724763\n",
      "Loss at step 1000: -2.144454892853175\n",
      "Loss at step 1500: -2.1561852189794983\n",
      "Loss at step 1790: -2.1586453004265276\n",
      "test.shape =  (20, 50, 1)\n",
      "tf.Tensor(\n",
      "[[1.         0.         0.5948599  0.5230495  0.33388672 0.59630182]\n",
      " [0.96431333 0.033364   0.62414104 0.31814793 0.59889922 0.22992065]\n",
      " [1.         0.07339831 0.97803386 0.         0.26182788 0.24413573]\n",
      " [1.         0.         0.34359097 0.30001371 0.25652953 0.29435554]\n",
      " [0.99393027 0.         0.7816348  0.30012353 0.53146403 0.20081217]\n",
      " [0.96708811 0.09128017 0.60659173 0.32644037 0.62454554 0.19198557]\n",
      " [1.         0.         0.46021453 0.588663   0.28264649 0.63339226]\n",
      " [1.         0.         0.69626783 0.70688458 0.37275538 0.18941989]\n",
      " [1.         0.38357425 0.5695568  0.64767268 0.27128041 0.67144544]\n",
      " [0.8328181  0.15726064 0.62536182 0.         0.43662238 0.        ]\n",
      " [1.         0.         0.96988795 0.16308997 0.25870915 0.24621968]\n",
      " [1.         0.0830538  0.71248901 0.39879888 0.60027122 0.23307843]\n",
      " [0.93856801 0.14833269 0.52907278 0.         0.57912621 0.10490343]\n",
      " [1.         0.         0.69684894 0.35549209 0.64995548 0.13096205]\n",
      " [0.75794867 0.20519505 0.5350795  0.60280982 0.31162318 0.65957942]\n",
      " [0.69041078 0.         0.88557125 0.21707233 0.44505331 0.16996872]\n",
      " [0.84774406 0.01649356 0.81813337 0.15929825 0.38936094 0.1342981 ]\n",
      " [0.5158654  0.         0.67861586 0.78590453 0.75268016 0.19573993]\n",
      " [1.         0.68256621 0.47656998 1.         0.17298342 0.97990428]\n",
      " [1.         0.05674512 0.55428631 0.54895061 0.31645818 0.60181931]], shape=(20, 6), dtype=float64)\n",
      "Evaluation 0: Calculating I\n",
      "Evaluation 0: Next query is tf.Tensor(\n",
      "[[1.         0.         0.58095238 0.5340388  0.3102359  0.56      ]\n",
      " [1.         0.         0.66340782 0.37337058 0.61206747 0.2       ]], shape=(2, 6), dtype=float64) with I value of 0.11030010204847843\n",
      "Evaluation 0: Training model\n",
      "Optimizer config:  {'name': 'RMSprop', 'learning_rate': 0.001, 'decay': 0.0, 'rho': 0.0, 'momentum': 0.0, 'epsilon': 1e-07, 'centered': False}\n",
      "Indifference_threshold is fixed at 0.0\n",
      "Initialize lengthscale at [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "       signal variance at 1.0\n",
      "   Initial negative ELBO: 257.5436123391647\n",
      "Negative ELBO at step 0: 255.27546194121314 in 0.1635s\n",
      "Negative ELBO at step 500: 14.417845537313614 in 52.1812s\n",
      "Negative ELBO at step 1000: 13.123916199402386 in 52.9888s\n",
      "Negative ELBO at step 1500: 12.727411230644053 in 52.0352s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d5217792c709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluation %s: Training model\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mevaluation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 model, inputs, u_mean, inducing_vars = train_and_visualize(X_temp, y_temp,\n\u001b[0;32m---> 45\u001b[0;31m                                                                            \"Run_{}_Evaluation_{}\".format(run, evaluation))\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-58cb62216760>\u001b[0m in \u001b[0;36mtrain_and_visualize\u001b[0;34m(X, y, title, lengthscale_init, signal_variance_init)\u001b[0m\n\u001b[1;32m     11\u001b[0m                         \u001b[0mn_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                         \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# only sample f values once, not re-sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                         num_steps=3000)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mq_mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'q_mu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/temp/sebtaysh/PBO/models/learning_fullgp.py\u001b[0m in \u001b[0;36mtrain_model_fullcov\u001b[0;34m(X, y, obj_low, obj_high, lengthscale_init, signal_variance_init, indifference_threshold, n_sample, deterministic, num_steps, lengthscale_lower_bound, regularizer_lengthscale_mean_over_range, regularizer_lengthscale_std_over_range)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_elbo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \"\"\"\n\u001b[1;32m    315\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[0;32m--> 316\u001b[0;31m         loss, var_list=var_list, grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clipnorm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_GatherV2Grad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     params_grad = _BatchGatherGrad(params_shape, values_transpose, indices,\n\u001b[0;32m--> 602\u001b[0;31m                                    batch_dims, params_shape[axis])\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Inverts the above transpose by moving dimension batch_dims back to its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_BatchGatherGrad\u001b[0;34m(params_shape, values, indices, batch_dims, gather_dim_size)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m   \u001b[0;31m# Axis is the first non-batch dimension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m   \u001b[0mindices_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0mvalues_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36msize\u001b[0;34m(input, name, out_type)\u001b[0m\n\u001b[1;32m    629\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m   \"\"\"\n\u001b[0;32m--> 631\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msize_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36msize_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[0mnp_out_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m     \u001b[0mnum_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_out_type\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_elements\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     if isinstance(\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1321\u001b[0m           \u001b[0;34m\"%sConversion function %r for type %s returned non-Tensor: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m           (_error_prefix(name), conversion_func, base_type, ret))\n\u001b[0;32m-> 1323\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m       raise RuntimeError(\n\u001b[1;32m   1325\u001b[0m           \u001b[0;34m\"%sConversion function %r for type %s returned incompatible \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/framework/dtypes.py\u001b[0m in \u001b[0;36mis_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     return self._type_enum in (other.as_datatype_enum,\n\u001b[0;32m--> 259\u001b[0;31m                                other.base_dtype.as_datatype_enum)\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/framework/dtypes.py\u001b[0m in \u001b[0;36mbase_dtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbase_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m\"\"\"Returns a non-reference `DType` based on this `DType`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_ref_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_INTERN_TABLE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_enum\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/framework/dtypes.py\u001b[0m in \u001b[0;36m_is_ref_dtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_is_ref_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m\"\"\"Returns `True` if this `DType` represents a reference type.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_enum\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for run in range(num_runs):  # CHECK IF STARTING RUN IS CORRECT\n",
    "    print(\"Beginning run %s\" % (run))\n",
    "    \n",
    "    X = init_vals[run]\n",
    "    y = get_noisy_observation(X, objective)\n",
    "    \n",
    "    model, inputs, u_mean, inducing_vars = train_and_visualize(X, y, \"Run_{}:_Initial_model\".format(run))\n",
    "\n",
    "    for evaluation in range(num_evals):\n",
    "        print(\"Beginning evaluation %s\" % (evaluation)) \n",
    "        \n",
    "        success = False\n",
    "        fail_count = 0\n",
    "        while not success:\n",
    "            # TODO: THIS ONLY WORKS FOR TOP-1 OF 2, CHANGE TO APPROPRIATE QUERY SAMPLING FOR HIGHER NUMBER OF CHOICES\n",
    "            samples = PBO.models.learning_fullgp.construct_input_pairs(inputs, features)\n",
    "\n",
    "            # Sample maximizers\n",
    "            print(\"Evaluation %s: Sampling maximizers\" % (evaluation))\n",
    "            maximizers = PBO.fourier_features.sample_maximizers(X=inducing_vars,\n",
    "                                                                count=num_maximizers,\n",
    "                                                                n_init=num_maximizers_init,\n",
    "                                                                D=num_fourier_features,\n",
    "                                                                model=model,\n",
    "                                                                min_val=objective_low,\n",
    "                                                                max_val=objective_high)\n",
    "            print(maximizers)\n",
    "\n",
    "            # Calculate PES value I for each possible next query\n",
    "            print(\"Evaluation %s: Calculating I\" % (evaluation))\n",
    "            I_vals = PBO.acquisitions.pes.I_batch(samples, maximizers, model)\n",
    "\n",
    "            # Select query that maximizes I\n",
    "            next_idx = np.argmax(I_vals)\n",
    "            next_query = samples[next_idx]\n",
    "            print(\"Evaluation %s: Next query is %s with I value of %s\" % (evaluation, next_query, I_vals[next_idx]))\n",
    "\n",
    "            X_temp = np.concatenate([X, [next_query]])\n",
    "            # Evaluate objective function\n",
    "            y_temp = np.concatenate([y, get_noisy_observation(np.expand_dims(next_query, axis=0), objective)], axis=0)\n",
    "            \n",
    "            try:\n",
    "                print(\"Evaluation %s: Training model\" % (evaluation))\n",
    "                model, inputs, u_mean, inducing_vars = train_and_visualize(X_temp, y_temp,\n",
    "                                                                           \"Run_{}_Evaluation_{}\".format(run, evaluation))\n",
    "                success = True\n",
    "\n",
    "            except ValueError as err:\n",
    "                print(err)\n",
    "                print(\"Retrying sampling random inputs\")\n",
    "                fail_count += 1\n",
    "\n",
    "            if fail_count >= 3:\n",
    "                print(\"Retry limit exceeded\")\n",
    "                raise ValueError(\"Failed\")\n",
    "                \n",
    "        \n",
    "        X = X_temp\n",
    "        y = y_temp\n",
    "        \n",
    "        # Save model\n",
    "        pickle.dump((X, y, inputs, \n",
    "                     model.kernel.variance, \n",
    "                     model.kernel.lengthscale, \n",
    "                     model.likelihood.variance, \n",
    "                     inducing_vars, \n",
    "                     model.q_mu, \n",
    "                     model.q_sqrt, \n",
    "                     maximizers), \n",
    "                    open(results_dir + \"Model_Run_{}_Evaluation_{}.p\".format(run, evaluation), \"wb\"))\n",
    "\n",
    "        (max_idx, rank) = get_max_sushi(model, features, rank_dict)\n",
    "        immediate_regret[run, evaluation] = rank - 1\n",
    "        \n",
    "        print(\"Maximizing sushi has index {} and rank {}\".format(max_idx, rank)) \n",
    "\n",
    "    X_results[run] = X\n",
    "    y_results[run] = y\n",
    "    print(\"Run {} immediate regret: \".format(run))\n",
    "    print(immediate_regret[run])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((X_results, y_results, immediate_regret), open(results_dir + \"res.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import umap\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_to_idx_dict = {}\n",
    "for i in range(len(fval_idx_tuples)):\n",
    "    rank_to_idx_dict[i+1] = fval_idx_tuples[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_results = immediate_regret + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_results = []\n",
    "for i in range(len(rank_results[0])):\n",
    "    idx_results.append(rank_to_idx_dict[rank_results[0][i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_plot = np.unique(idx_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = [\"8, 10\", \"5, 7, 9\", \"6\", \"11\", \"1\", \"2, 4\", \"3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_orders_tuples = list(zip(idx_to_plot, orders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [41, 47, 79, 47, 21, 27, 21, 11, 21, 11, 37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_order_tuples = list(zip(order, range(1, len(order)+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "obj_model = gpflow.models.VGP(data=(features, np.expand_dims(fvals, axis=-1)),\n",
    "                             kernel=gpflow.kernels.RBF(lengthscale=[0.1 for i in range(len(features[0]))]),\n",
    "                             likelihood=gpflow.likelihoods.Gaussian())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_summary(obj_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = gpflow.optimizers.Scipy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.minimize(lambda: -obj_model.log_likelihood(), obj_model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_summary(obj_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_fvals = np.squeeze(obj_model.predict_f(features)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_embed = pca.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = X_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_shape = queries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "for query in queries.reshape([-1, 6]):\n",
    "    ranks.append(rank_dict[query.data.tobytes()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_idxs = []\n",
    "for rank in ranks:\n",
    "    line_idxs.append(rank_to_idx_dict[rank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = np.reshape(line_idxs, queries_shape[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=200)\n",
    "plt.plot(range(7, 42), np.squeeze(immediate_regret))\n",
    "plt.title(\"Immediate regret\")\n",
    "plt.xlabel(\"Evaluations\")\n",
    "plt.ylabel(\"IR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=200)\n",
    "plt.scatter(pca_embed[:, 0], pca_embed[:, 1], c=fvals, cmap='Spectral')\n",
    "for tup in idx_orders_tuples:\n",
    "    plt.text(pca_embed[tup[0], 0], pca_embed[tup[0], 1], str(tup[1]))\n",
    "for pair in final:\n",
    "    x_vals = [pca_embed[pair[0], 0], pca_embed[pair[1], 0]]\n",
    "    y_vals = [pca_embed[pair[0], 1], pca_embed[pair[1], 1]]\n",
    "    plt.plot(x_vals, y_vals, linestyle='dashed', linewidth=0.5, color='gray' )\n",
    "plt.colorbar()\n",
    "plt.title(\"PCA with local maxima and queries\")\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=200)\n",
    "plt.scatter(pca_embed[:, 0], pca_embed[:, 1], c=gp_fvals, cmap='Spectral')\n",
    "for tup in idx_orders_tuples:\n",
    "    plt.text(pca_embed[tup[0], 0], pca_embed[tup[0], 1], str(tup[1]))\n",
    "for pair in final:\n",
    "    x_vals = [pca_embed[pair[0], 0], pca_embed[pair[1], 0]]\n",
    "    y_vals = [pca_embed[pair[0], 1], pca_embed[pair[1], 1]]\n",
    "    plt.plot(x_vals, y_vals, linestyle='dashed', linewidth=0.5, color='gray' )\n",
    "plt.colorbar()\n",
    "plt.title(\"PCA with local maxima and queries (GP posterior mean fvals)\")\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "umap_embed = reducer.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=200)\n",
    "plt.scatter(umap_embed[:, 0], umap_embed[:, 1], c=fvals, cmap='Spectral')\n",
    "for tup in idx_orders_tuples:\n",
    "    plt.text(umap_embed[tup[0], 0], umap_embed[tup[0], 1], str(tup[1]))\n",
    "for pair in final:\n",
    "    x_vals = [umap_embed[pair[0], 0], umap_embed[pair[1], 0]]\n",
    "    y_vals = [umap_embed[pair[0], 1], umap_embed[pair[1], 1]]\n",
    "    plt.plot(x_vals, y_vals, linestyle='dashed', linewidth=0.5, color='gray' )\n",
    "plt.colorbar()\n",
    "plt.title(\"UMAP with local maxima and queries\")\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=200)\n",
    "plt.scatter(umap_embed[:, 0], umap_embed[:, 1], c=gp_fvals, cmap='Spectral')\n",
    "for tup in idx_orders_tuples:\n",
    "    plt.text(umap_embed[tup[0], 0], umap_embed[tup[0], 1], str(tup[1]))\n",
    "for pair in final:\n",
    "    x_vals = [umap_embed[pair[0], 0], umap_embed[pair[1], 0]]\n",
    "    y_vals = [umap_embed[pair[0], 1], umap_embed[pair[1], 1]]\n",
    "    plt.plot(x_vals, y_vals, linestyle='dashed', linewidth=0.5, color='gray' )\n",
    "plt.colorbar()\n",
    "plt.title(\"UMAP with local maxima and queries\")\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X, y = features, fvals\n",
    "# define the model\n",
    "model = LinearRegression()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# get importance\n",
    "importance = model.coef_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.figure(figsize=(10, 5), dpi=200)\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.title(\"Feature importance from linear regression coefficients\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Importance score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5), dpi=200)\n",
    "plt.scatter(features[:, -3], fvals)\n",
    "plt.title(\"Feature 3 (how frequently the sushi is eaten)\")\n",
    "plt.ylabel(\"$f_x$\")\n",
    "plt.xlabel(\"$x_3$\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
