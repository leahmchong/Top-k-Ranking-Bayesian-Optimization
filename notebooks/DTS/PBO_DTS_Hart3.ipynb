{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preferential Bayesian Optimization: Dueling-Thompson Sampling\n",
    "\n",
    "Implementation of the algorithm by Gonzalez et al (2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "from gpflow.utilities import set_trainable, print_summary\n",
    "gpflow.config.set_default_summary_fmt(\"notebook\")\n",
    "\n",
    "sys.path.append(os.path.split(os.path.split(os.path.split(os.getcwd())[0])[0])[0]) # Move 3 levels up directory to import PBO\n",
    "import PBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpu_to_use = 0\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_visible_devices(gpus[gpu_to_use], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(message):\n",
    "    print(str(datetime.datetime.now()) + ': ' + message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = PBO.objectives.hartmann3d\n",
    "objective_low = 0.\n",
    "objective_high = 1.\n",
    "objective_name = \"Hart3\"\n",
    "acquisition_name = \"DTS\"\n",
    "experiment_name = \"PBO\" + \"_\" + acquisition_name + \"_\" + objective_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 20\n",
    "num_evals = 20\n",
    "num_samples = 100\n",
    "num_choices = 2\n",
    "input_dims = 3\n",
    "num_maximizers = 20\n",
    "num_init_points = 3\n",
    "num_inducing_init = 3\n",
    "num_discrete_per_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  /home/seb/PBO/notebooks/DTS/results/PBO_DTS_Hart3/  created \n"
     ]
    }
   ],
   "source": [
    "results_dir = os.getcwd() + '/results/' + experiment_name + '/'\n",
    "\n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.makedirs(results_dir)\n",
    "    print(\"Directory \" , results_dir ,  \" created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , results_dir ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_model(query_points, y, m, title=\"Model\", cmap=\"Spectral\"):\n",
    "    if query_points.shape[-1] != 2:\n",
    "        return\n",
    "\n",
    "    pos_vals = []\n",
    "    neg_vals = []\n",
    "    for i in range(len(y)):\n",
    "        if y[i]:\n",
    "            pos_vals.append(query_points[i])\n",
    "        else:\n",
    "            neg_vals.append(query_points[i])\n",
    "    pos_vals = np.array(pos_vals)\n",
    "    neg_vals = np.array(neg_vals)\n",
    "\n",
    "    num_discrete_points = num_discrete_per_dim\n",
    "    side = np.linspace(0, 1, num_discrete_points)\n",
    "    X,Y = np.meshgrid(side,side)\n",
    "    preds = tf.transpose(tf.reshape(m.predict_y(combs)[0], [num_discrete_points, num_discrete_points]))\n",
    "    variances = tf.transpose(tf.reshape(PBO.acquisitions.dts.variance_logistic_f(m, combs), [num_discrete_points, num_discrete_points]))\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle(title)\n",
    "    fig.set_size_inches(18.5, 6.88)\n",
    "    fig.set_dpi((200))\n",
    "    \n",
    "    ax1.axis('equal')\n",
    "    if len(pos_vals) != 0:\n",
    "        ax1.scatter(*pos_vals.T, c=\"black\", marker=\"o\")\n",
    "    if len(neg_vals) != 0:\n",
    "        ax1.scatter(*neg_vals.T, c=\"black\", marker=\"x\")\n",
    "    im1 = ax1.imshow(preds, interpolation='nearest', extent=(0.0, 1.0, 0.0, 1.0), origin='lower', cmap=cmap)\n",
    "    ax1.set_title(\"Mean of y(x, x')\")\n",
    "    ax1.set_xlabel(\"x\")\n",
    "    ax1.set_ylabel(\"x'\")\n",
    "    ax1.axvline(x=0.757, linestyle='--')\n",
    "    fig.colorbar(im1, ax=ax1)\n",
    "\n",
    "    ax2.axis('equal')\n",
    "    if len(pos_vals) != 0:\n",
    "        ax2.scatter(*pos_vals.T, c=\"black\", marker=\"o\")\n",
    "    if len(neg_vals) != 0:\n",
    "        ax2.scatter(*neg_vals.T, c=\"black\", marker=\"x\")\n",
    "    im2 = ax2.imshow(variances, interpolation='nearest', extent=(0.0, 1.0, 0.0, 1.0), origin='lower', cmap=cmap)\n",
    "    ax2.set_title(\"Variance of y(x, x')\")\n",
    "    ax2.set_xlabel(\"x\")\n",
    "    ax2.set_ylabel(\"x'\")\n",
    "    fig.colorbar(im2, ax=ax2)\n",
    "    \n",
    "    plt.savefig(fname=results_dir + title + \".png\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_f_sample(f_vals, cmap=\"Spectral\"):\n",
    "    fig, (ax1) = plt.subplots(1)\n",
    "    fig.suptitle('Sampled f values')\n",
    "    fig.set_size_inches(4, 3.3)\n",
    "    fig.set_dpi((100))\n",
    "    \n",
    "    ax1.axis('equal')\n",
    "    im1 = ax1.imshow(tf.transpose(tf.reshape(f_vals, [num_discrete_points, num_discrete_points])),\n",
    "                     interpolation='nearest', extent=(0.0, 1.0, 0.0, 1.0), origin='lower', cmap=cmap)\n",
    "    ax1.set_xlabel(\"x\")\n",
    "    ax1.set_ylabel(\"x'\")\n",
    "    ax1.axvline(x=0.757, linestyle='--')\n",
    "    fig.colorbar(im1, ax=ax1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_representation(X, num_choices):\n",
    "    \"\"\"\n",
    "    :param X: tensor of shape (num_data, input_dims * num_choices)\n",
    "    :return: tensor of shape (num_data, num_choices, input_dims)\n",
    "    \"\"\"\n",
    "    input_dims = X.shape[-1] // num_choices\n",
    "    ret_val = np.zeros((X.shape[0], num_choices, input_dims))\n",
    "    \n",
    "    for i in range(num_choices):\n",
    "        ret_val[:, i, :] = X[:, input_dims*i:input_dims*(i+1)]\n",
    "        \n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noisy_observation_dts(X, objective):\n",
    "    \"\"\"\n",
    "    :param X: tensor of shape (num_data, input_dims * 2)\n",
    "    :param objective: objective function\n",
    "    \"\"\"\n",
    "    num_data = X.shape[0]\n",
    "    X_std = std_representation(X, num_choices) # (num_data, num_choices, input_dims)\n",
    "    f = PBO.objectives.objective_get_f_neg(X_std, objective)\n",
    "    obs = np.array(PBO.observation_model.gen_observation_from_f(X_std, f, 1))  # (num_data, 1, input_dims)\n",
    "\n",
    "    ret_val = np.zeros((num_data, 1), dtype=np.int8)\n",
    "    for i in range(num_data):\n",
    "        if np.allclose(X_std[i, 0], obs[i, 0]):\n",
    "            ret_val[i] = 1\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizer_lengthscale_mean_over_range = 0.2\n",
    "regularizer_lengthscale_std_over_range = 0.5\n",
    "input_range = objective_high - objective_low\n",
    "lengthscale_mean_regularizer = input_range * regularizer_lengthscale_mean_over_range\n",
    "lengthscale_std_regularizer = input_range * regularizer_lengthscale_std_over_range\n",
    "lengthscale = lengthscale_mean_regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def lengthscale_regularizer(kernel):  # for product kernel\n",
    "    loss = 0\n",
    "    for k in kernel.kernels:\n",
    "        loss += 0.5 * tf.reduce_sum(tf.square((k.lengthscale - lengthscale_mean_regularizer) / lengthscale_std_regularizer))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_visualize(X, y, lengthscale, title, num_steps=3000):\n",
    "    kernel = gpflow.kernels.Product([gpflow.kernels.RBF(lengthscale=lengthscale, \n",
    "                                                        active_dims=[i, i+input_dims]) \n",
    "                                     for i in range(input_dims)])\n",
    "    \n",
    "    m = gpflow.models.SVGP(kernel=kernel,\n",
    "                           likelihood=gpflow.likelihoods.Bernoulli(invlink=tf.math.sigmoid),\n",
    "                           inducing_variable=X,\n",
    "                           whiten=False)\n",
    "    \n",
    "    m.inducing_variable.Z.trainable = False\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.RMSprop(rho=0.0)\n",
    "    \n",
    "    loss = lambda: -m.log_likelihood(X, y) + lengthscale_regularizer(m.kernel)\n",
    "    prev_loss = loss().numpy()\n",
    "    \n",
    "    for i in range(num_steps):\n",
    "        optimizer.minimize(loss, m.trainable_variables)\n",
    "        current_loss = loss().numpy()\n",
    "        if i % 500 == 0:\n",
    "            print('Loss at step %s: %s' % (i, current_loss))\n",
    "        if abs((current_loss-prev_loss) / prev_loss) < 1e-7:\n",
    "            print('Loss at step %s: %s' % (i, current_loss))\n",
    "            break\n",
    "        prev_loss = current_loss\n",
    "        \n",
    "    visualize_model(X, y, m, title=title)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_grid(input_dims, num_discrete_per_dim, low, high):\n",
    "    \"\"\"\n",
    "    Returns an array with all possible permutations of discrete values in input_dims number of dimensions.\n",
    "    :param input_dims: int\n",
    "    :param num_discrete_per_dim: int\n",
    "    :param low: int\n",
    "    :param high: int\n",
    "    :return: tensor of shape (num_discrete_per_dim ** input_dims, input_dims)\n",
    "    \"\"\"\n",
    "    num_points = num_discrete_per_dim ** input_dims\n",
    "    out = np.zeros([num_points, input_dims])\n",
    "    discrete_points = np.linspace(low, high, num_discrete_per_dim)\n",
    "    for i in range(num_points):\n",
    "        for dim in range(input_dims):\n",
    "            val = num_discrete_per_dim ** (dim)\n",
    "            out[i, dim] = discrete_points[int((i // val) % num_discrete_per_dim)]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_guess(m, discrete_space, combs):\n",
    "    return PBO.acquisitions.dts.soft_copeland_maximizer(m.predict_y(combs)[0], discrete_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(X):\n",
    "    \"\"\"\n",
    "    :param X: tensor of shape (num_data, input_dims * 2)\n",
    "    :return: tensor of shape (num_data, input_dims * 2), where the first input_dims is swapped with the second\n",
    "    \"\"\"\n",
    "    input_dims = X.shape[-1] // 2\n",
    "    ret_val = np.zeros((X.shape))\n",
    "    for i in range(X.shape[0]):\n",
    "        ret_val[i, :input_dims] = X[i, input_dims:]\n",
    "        ret_val[i, input_dims:] = X[i, :input_dims]\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_y(y):\n",
    "    \"\"\"\n",
    "    :param y: tensor of shape (num_data, 1), with int values either 0 or 1\n",
    "    \"\"\"\n",
    "    return (y + 1) % 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the initial values for each run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "init_points = np.random.uniform(low=objective_low, high=objective_high, size=[num_runs, num_init_points, input_dims])\n",
    "num_combs = int((num_init_points-1) * num_init_points / 2)\n",
    "init_vals = np.zeros([num_runs, num_combs, num_choices, input_dims])\n",
    "for run in range(num_runs):\n",
    "    cur_idx = 0\n",
    "    for init_point in range(num_init_points-1):\n",
    "        for next_point in range(init_point+1, num_init_points):\n",
    "            init_vals[run, cur_idx, 0] = init_points[run, init_point]\n",
    "            init_vals[run, cur_idx, 1] = init_points[run, next_point]\n",
    "            cur_idx += 1\n",
    "\n",
    "init_vals = np.reshape(init_vals, [num_runs, num_combs, num_choices * input_dims])\n",
    "# symmetric_vals = np.flip(init_vals, axis=-2)\n",
    "# symmetric_points = np.reshape(symmetric_vals, [num_runs, num_combs, num_choices * input_dims])\n",
    "\n",
    "# init_vals = np.concatenate([init_points, symmetric_points], axis=-2)  # Model always has info about symmetric points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discrete_space = uniform_grid(input_dims, num_discrete_per_dim, objective_low, objective_high)\n",
    "combs = PBO.acquisitions.dts.combinations(discrete_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the results in these arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_at_end = (num_combs + num_evals) * 2\n",
    "X_results = np.zeros([num_runs, num_data_at_end, input_dims * num_choices])\n",
    "y_results = np.zeros([num_runs, num_data_at_end, 1])\n",
    "best_guess_results = np.zeros([num_runs, num_evals, input_dims])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-07 20:05:29.899050: Starting run 0\n",
      "Loss at step 0: 4.98589755184286\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<class 'tensorflow.python.framework.ops.EagerTensor'> returned a result with an error set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   7430\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Reshape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7431\u001b[0;31m         tld.op_callbacks, tensor, shape)\n\u001b[0m\u001b[1;32m   7432\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: Expected `context` argument in EagerTensor constructor to have a `_handle` attribute but it did not. Was eager Context initialized?",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c83004bd2e5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflip_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_and_visualize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengthscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlengthscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Run_{}_Initial_model\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#TODO: CHECK LENGTHSCALE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_evals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-fcabe0678230>\u001b[0m in \u001b[0;36mtrain_and_visualize\u001b[0;34m(X, y, lengthscale, title, num_steps)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mcurrent_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \"\"\"\n\u001b[1;32m    315\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[0;32m--> 316\u001b[0;31m         loss, var_list=var_list, grad_loss=grad_loss)\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"clipnorm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_TileGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    737\u001b[0m   \u001b[0;31m#   axes = [0, 2, 4]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m   split_shape = array_ops.reshape(\n\u001b[0;32m--> 739\u001b[0;31m       array_ops.transpose(array_ops.stack([op.inputs[1], input_shape])), [-1])\n\u001b[0m\u001b[1;32m    740\u001b[0m   \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m   \u001b[0;31m# Sum reduces grad along the first dimension for IndexedSlices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m   \"\"\"\n\u001b[0;32m--> 193\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   7434\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7435\u001b[0m         return reshape_eager_fallback(\n\u001b[0;32m-> 7436\u001b[0;31m             tensor, shape, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   7437\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7438\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape_eager_fallback\u001b[0;34m(tensor, shape, name, ctx)\u001b[0m\n\u001b[1;32m   7457\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreshape_eager_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7458\u001b[0m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7459\u001b[0;31m   \u001b[0m_attr_Tshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7460\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7461\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tshape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, default_dtype)\u001b[0m\n\u001b[1;32m    261\u001b[0m       ret.append(\n\u001b[1;32m    262\u001b[0m           ops.convert_to_tensor(\n\u001b[0;32m--> 263\u001b[0;31m               t, dtype, preferred_dtype=default_dtype, ctx=ctx))\n\u001b[0m\u001b[1;32m    264\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1300\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         ret = conversion_func(\n\u001b[0;32m-> 1302\u001b[0;31m             value, dtype=preferred_dtype, name=name, as_ref=as_ref)\n\u001b[0m\u001b[1;32m   1303\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0;31m# Could not coerce the conversion to use the preferred dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    315\u001b[0m                                          as_ref=False):\n\u001b[1;32m    316\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    256\u001b[0m   \"\"\"\n\u001b[1;32m    257\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 258\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    264\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gpflow/lib/python3.6/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemError\u001b[0m: <class 'tensorflow.python.framework.ops.EagerTensor'> returned a result with an error set"
     ]
    }
   ],
   "source": [
    "for run in range(num_runs):\n",
    "    log(\"Starting run {}\".format(run))\n",
    "    #Fit a GP with kernel k to Dn\n",
    "    \n",
    "    X = init_vals[run]\n",
    "    y = get_noisy_observation_dts(X, objective)\n",
    "    \n",
    "    X = np.vstack([X, flip(X)])\n",
    "    y = np.vstack([y, flip_y(y)])\n",
    "    \n",
    "    model = train_and_visualize(X, y, lengthscale=lengthscale, title=\"Run_{}_Initial_model\".format(run))  #TODO: CHECK LENGTHSCALE\n",
    "    \n",
    "    for evaluation in range(num_evals):\n",
    "        log(\"Starting evaluation \" + str(evaluation))\n",
    "        \n",
    "        # Sample f using RFF\n",
    "        f_vals = PBO.acquisitions.dts.sample_f(model, X, combs)\n",
    "\n",
    "        # 2 and 3. Compute the acquisition for duels alpha and get next duel\n",
    "        log(\"Computing acquisition function\")\n",
    "        x_next = PBO.acquisitions.dts.soft_copeland_maximizer(f_vals, discrete_space)        \n",
    "        \n",
    "        all_pairs = np.concatenate([np.tile(x_next, (discrete_space.shape[0], 1)), discrete_space], axis=1)\n",
    "        next_vars = np.squeeze(PBO.acquisitions.dts.variance_logistic_f(model, all_pairs), \n",
    "                               axis=1)\n",
    "        xprime_next = discrete_space[np.argmax(next_vars)]\n",
    "        \n",
    "        x_xprime_next = np.expand_dims(np.concatenate([x_next, xprime_next]), axis=0)\n",
    "        \n",
    "        # Change by random small values otherwise Fourier features matrix becomes non-invertible\n",
    "        if np.all(np.equal(x_xprime_next, flip(x_xprime_next))) or x_xprime_next in X:\n",
    "            for i in range(len(x_xprime_next[0])):\n",
    "                if x_xprime_next[0][i] < 0.5:\n",
    "                    x_xprime_next[0][i] += np.random.uniform(low=0., high=1e-3)\n",
    "                else:\n",
    "                    x_xprime_next[0][i] -= np.random.uniform(low=0., high=1e-3)\n",
    "        \n",
    "        log(\"x and x_prime: \\n\" + str(x_xprime_next))\n",
    "        \n",
    "        # 4. Run the duel and get y\n",
    "        y_next = get_noisy_observation_dts(x_xprime_next, objective)\n",
    "        log(\"y_next: \\n\" + str(y_next))\n",
    "        \n",
    "        # 5. Augment X and Y, and add symmetric points\n",
    "        X = np.vstack([X, x_xprime_next, flip(x_xprime_next)])\n",
    "        y = np.vstack([y, y_next, flip_y(y_next)])\n",
    "        \n",
    "        # Fit a GP with kernel k to Dj and learn pi(x).\n",
    "        model = train_and_visualize(X, y, lengthscale=lengthscale, title=\"Run_{}_Evaluation_{}\".format(run, evaluation))\n",
    "        \n",
    "        # Save model\n",
    "        kernels_variance = []\n",
    "        kernels_lengthscale = []\n",
    "        for k in model.kernel.kernels:\n",
    "            kernels_variance.append(k.variance.numpy())\n",
    "            kernels_lengthscale.append(k.lengthscale.numpy())\n",
    "\n",
    "        pickle.dump((X, y, \n",
    "                    tuple(kernels_variance),\n",
    "                    tuple(kernels_lengthscale),\n",
    "                    model.q_mu.numpy(),\n",
    "                    model.q_sqrt.numpy()), \n",
    "                 open(results_dir + \"Model_Run_{}_Evaluation_{}.p\".format(run, evaluation), \"wb\"))\n",
    "        \n",
    "        # Get current best guess\n",
    "        best_guess_results[run, evaluation] = best_guess(model, discrete_space, combs)\n",
    "\n",
    "    X_results[run] = X\n",
    "    y_results[run] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((X_results, y_results, best_guess_results), open(results_dir + \"Xybestguess.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
