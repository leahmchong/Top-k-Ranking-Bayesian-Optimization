{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preferential Bayesian Optimization: EI\n",
    "This notebook demonstrates the use of the Expected Improvement (EI) acquisition function on ordinal (preference) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from gpflow.utilities import set_trainable, print_summary\n",
    "gpflow.config.set_default_summary_fmt(\"notebook\")\n",
    "\n",
    "sys.path.append(os.path.split(os.path.split(os.path.split(os.getcwd())[0])[0])[0]) # Move 3 levels up directory to import PBO\n",
    "import PBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_to_use = 0\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_visible_devices(gpus[gpu_to_use], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengthscale = 0.05\n",
    "lengthscale_prior_alpha = tf.constant(2, dtype=tf.float64)\n",
    "lengthscale_prior_beta = tf.constant(4, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = PBO.objectives.forrester\n",
    "objective_low = 0.\n",
    "objective_high = 1.\n",
    "objective_name = \"Forrester\"\n",
    "acquisition_name = \"EI\"\n",
    "experiment_name = acquisition_name + \"_\" + objective_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 10\n",
    "num_evals = 20\n",
    "num_choices = 2\n",
    "input_dims = 1\n",
    "objective_dim = input_dims # CHANGE 1: require the objective dim\n",
    "num_maximizers = 20\n",
    "num_init_prefs = 5 # CHANGE 2: randomly initialize with some preferences\n",
    "\n",
    "# CHANGE 1: reduce the value of delta to avoid numerical error\n",
    "# as k(x,x') = sigma^2 * exp( -[(x-x')/l]^2 )\n",
    "# which could be very small if l is too small\n",
    "# so we define l relatively by the range of input (objective_high - objective_low)\n",
    "#   It is ok for the total number of observations > the total number of possible inputs\n",
    "# because there is a noise in the observation, it might require repeated observations \n",
    "# at the same input pair to improve the confidence \n",
    "num_discrete_per_dim = 60\n",
    "delta = (objective_high - objective_low) / num_discrete_per_dim\n",
    "num_samples = num_discrete_per_dim-1  # for 1-D case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = os.getcwd() + '/results/' + experiment_name + '/'\n",
    "\n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.makedirs(results_dir)\n",
    "    print(\"Directory \" , results_dir ,  \" created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , results_dir ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the Forrester function (global min at ~0.757):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.linspace(0.0, 1.0, 100).reshape(100, 1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(xx, objective(xx), 'C0', linewidth=1)\n",
    "plt.xlim(-0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gp(model, X, y, title, cmap=\"Spectral\"):\n",
    "    #Plotting code from GPflow authors\n",
    "\n",
    "    ## generate test points for prediction\n",
    "    xx = np.linspace(-0.1, 1.1, 100).reshape(100, 1)  # test points must be of shape (N, D)\n",
    "\n",
    "    ## predict mean and variance of latent GP at test points\n",
    "    mean, var = model.predict_f(xx)\n",
    "\n",
    "    ## generate 10 samples from posterior\n",
    "    samples = model.predict_f_samples(xx, 10)  # shape (10, 100, 1)\n",
    "\n",
    "    ## plot \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(X, y, 'kx', mew=2)\n",
    "    plt.plot(xx, mean, 'C0', lw=2)\n",
    "    plt.fill_between(xx[:,0],\n",
    "                     mean[:,0] - 1.96 * np.sqrt(var[:,0]),\n",
    "                     mean[:,0] + 1.96 * np.sqrt(var[:,0]),\n",
    "                     color='C0', alpha=0.2)\n",
    "\n",
    "    plt.plot(xx, samples[:, :, 0].numpy().T, 'C0', linewidth=.5)\n",
    "    plt.xlim(-0.1, 1.1)\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.savefig(fname=results_dir + title + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noisy_observation(X, objective):\n",
    "    f = PBO.objectives.objective_get_f_neg(X, objective)\n",
    "    return PBO.observation_model.gen_observation_from_f(X, f, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_visualize(X, y, title, lengthscale_init=None, signal_variance_init=None):\n",
    "    lengthscale_prior = tfp.distributions.Gamma(concentration=lengthscale_prior_alpha,\n",
    "                                               rate=lengthscale_prior_beta)\n",
    "    \n",
    "    # Train model with data\n",
    "    # CHANGE 6: use full_gp instead of sparse, \n",
    "    result = PBO.models.learning_fullgp.train_model_fullcov(\n",
    "                        X, y, \n",
    "                        obj_low=objective_low,\n",
    "                        obj_high=objective_high,\n",
    "                        lengthscale_init=lengthscale_init,\n",
    "                        signal_variance_init=signal_variance_init,\n",
    "                        indifference_threshold=0.,\n",
    "                        n_sample=1000,\n",
    "                        deterministic=True, # only sample f values once, not re-sampling\n",
    "                        num_steps=3000)\n",
    "    \n",
    "    q_mu = result['q_mu']\n",
    "    q_sqrt = result['q_sqrt']\n",
    "    u = result['u']\n",
    "    inputs = result['inputs']\n",
    "    k = result['kernel']\n",
    "    \n",
    "    likelihood = gpflow.likelihoods.Gaussian()\n",
    "    model = PBO.models.learning.init_SVGP_fullcov(q_mu, q_sqrt, u, k, likelihood)\n",
    "    u_mean = q_mu.numpy()\n",
    "    inducing_vars = u.numpy()\n",
    "    \n",
    "    # Visualize model\n",
    "    plot_gp(model, inducing_vars, u_mean, title)\n",
    "    \n",
    "    return model, inputs, u_mean, inducing_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniform_grid(input_dims, num_discrete_per_dim, low=0., high=1.):\n",
    "    \"\"\"\n",
    "    Returns an array with all possible permutations of discrete values in input_dims number of dimensions.\n",
    "    :param input_dims: int\n",
    "    :param num_discrete_per_dim: int\n",
    "    :param low: int\n",
    "    :param high: int\n",
    "    :return: tensor of shape (num_discrete_per_dim ** input_dims, input_dims)\n",
    "    \"\"\"\n",
    "    num_points = num_discrete_per_dim ** input_dims\n",
    "    out = np.zeros([num_points, input_dims])\n",
    "    discrete_points = np.linspace(low, high, num_discrete_per_dim)\n",
    "    for i in range(num_points):\n",
    "        for dim in range(input_dims):\n",
    "            val = num_discrete_per_dim ** (dim)\n",
    "            out[i, dim] = discrete_points[int((i // val) % num_discrete_per_dim)]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is our main metric for the performance of the acquisition function: The closer the model's best guess to the target (in this case, the global minimum of the Forrester function), the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_guess(model):\n",
    "    \"\"\"\n",
    "    Returns a GP model's best guess of the global maximum of f.\n",
    "    \"\"\"\n",
    "    # CHANGE 7: use a discrete grid\n",
    "    xx = PBO.models.learning_fullgp.get_all_discrete_inputs(objective_low, objective_high, objective_dim, delta)\n",
    "    res = model.predict_f(xx)[0].numpy()\n",
    "    return xx[np.argmax(res)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the results in these arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_at_end = int(num_init_prefs + num_evals)\n",
    "X_results = np.zeros([num_runs, num_data_at_end, num_choices, input_dims])\n",
    "y_results = np.zeros([num_runs, num_data_at_end, 1, input_dims])\n",
    "best_guess_results = np.zeros([num_runs, num_evals, input_dims])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the initial values for each run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# CHANGE 8: just randomly initialize with some preference observation\n",
    "init_vals = np.zeros([num_runs, num_init_prefs, num_choices, input_dims])\n",
    "\n",
    "for run in range(num_runs):\n",
    "    for i in range(num_init_prefs):\n",
    "        init_vals[run,i] = PBO.models.learning_fullgp.get_random_inputs(\n",
    "                                objective_low, \n",
    "                                objective_high, \n",
    "                                objective_dim, \n",
    "                                delta,\n",
    "                                size=num_choices,\n",
    "                                with_replacement=False,\n",
    "                                exclude_inputs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loops carry out the Bayesian optimization algorithm over a number of runs, with a fixed number of evaluations per run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# CHANGE 9: need to store lengthscale and signal_variance from previous iteration to initialize the current iteration\n",
    "lengthscale_init = None\n",
    "signal_variance_init = None\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(\"\")\n",
    "    print(\"==================\")\n",
    "    print(\"Beginning run %s\" % (run))\n",
    "    \n",
    "    X = init_vals[run]\n",
    "    y = get_noisy_observation(X, objective)\n",
    "    \n",
    "    model, inputs, u_mean, inducing_vars = train_and_visualize(X, y, \n",
    "                                                        \"Run_{}:_Initial_model\".format(run))\n",
    "    # save optimized lengthscale and signal variance for next iteration\n",
    "    lengthscale_init = model.kernel.lengthscale.numpy()\n",
    "    signal_variance_init = model.kernel.variance.numpy()\n",
    "    \n",
    "    for evaluation in range(num_evals):\n",
    "        print(\"Beginning evaluation %s\" % (evaluation)) \n",
    "\n",
    "        # Get incumbent maximizer\n",
    "        input_vals = model.predict_f(inputs)[0].numpy()\n",
    "        maximizer = np.expand_dims(inputs[np.argmax(input_vals)], axis=0)\n",
    "        \n",
    "        print(\"Maximizer:\")\n",
    "        print(maximizer)\n",
    "        \n",
    "        # Sample possible next input points. In EI, all queries are a pair with the incumbent maximizer as the \n",
    "        # first point and a next input point as the second point\n",
    "        \n",
    "        samples = PBO.models.learning_fullgp.get_random_inputs(low=objective_low,\n",
    "                                                       high=objective_high,\n",
    "                                                       dim=objective_dim,\n",
    "                                                       delta=delta,\n",
    "                                                       size=num_samples,\n",
    "                                                       exclude_inputs=maximizer)\n",
    "        \n",
    "        # Calculate EI vals\n",
    "        ei_vals = PBO.acquisitions.ei.EI(model, maximizer, samples)\n",
    "        L = np.argsort(np.ravel(-ei_vals))  # n-th element in this (num_samples, ) size array is the index of n-th\n",
    "        #largest element in ei_vals\n",
    "        \n",
    "        # Select query that maximizes EI\n",
    "        if np.all(np.equal(samples[L[0]], maximizer)):  #if value with highest EI is same as maximizer, pick the next\n",
    "            # highest value. Else pick this\n",
    "            next_idx = L[1]\n",
    "        else:\n",
    "            next_idx = L[0]\n",
    "            \n",
    "        next_query = np.zeros((num_choices, input_dims))\n",
    "        next_query[0, :] = maximizer  # EI only works in binary choices\n",
    "        next_query[1, :] = samples[next_idx]\n",
    "        print(\"Evaluation %s: Next query is %s with EI value of %s\" % (evaluation, next_query, ei_vals[next_idx]))\n",
    "\n",
    "        X = np.concatenate([X, [next_query]])\n",
    "        # Evaluate objective function\n",
    "        y = np.concatenate([y, get_noisy_observation(np.expand_dims(next_query, axis=0), objective)], axis=0)\n",
    "        \n",
    "        print(\"Evaluation %s: Training model\" % (evaluation))\n",
    "        model, inputs, u_mean, inducing_vars = train_and_visualize(X, y,  \n",
    "                                                                   \"Run_{}_Evaluation_{}\".format(run, evaluation))\n",
    "        print_summary(model)\n",
    "\n",
    "        # save optimized lengthscale and signal variance for next iteration\n",
    "        lengthscale_init = model.kernel.lengthscale.numpy()\n",
    "        signal_variance_init = model.kernel.variance.numpy()\n",
    "\n",
    "        best_guess_results[run, evaluation, :] = best_guess(model)\n",
    "        # CHANGE 11: log both the estimated minimizer and its objective value\n",
    "        print(\"Best_guess f({}) = {}\".format(\n",
    "                best_guess_results[run, evaluation, :], \n",
    "                objective(best_guess_results[run, evaluation, :])))\n",
    "        \n",
    "        # Save model\n",
    "        pickle.dump((X, y, inputs, \n",
    "                     model.kernel.variance, \n",
    "                     model.kernel.lengthscale, \n",
    "                     model.likelihood.variance, \n",
    "                     inducing_vars, \n",
    "                     model.q_mu, \n",
    "                     model.q_sqrt, \n",
    "                     maximizer), \n",
    "                    open(results_dir + \"Model_Run_{}_Evaluation_{}.p\".format(run, evaluation), \"wb\"))\n",
    "\n",
    "    X_results[run] = X\n",
    "    y_results[run] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((X_results, y_results, best_guess_results), \n",
    "            open(results_dir + acquisition_name + \"_\" + objective_name + \"_\" + \"Xybestguess.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_min = np.min(objective(PBO.models.learning_fullgp.get_all_discrete_inputs(objective_low, objective_high, objective_dim, delta)))\n",
    "metric = best_guess_results\n",
    "ir = objective(metric) - global_min\n",
    "mean = np.mean(ir, axis=0)\n",
    "std_dev = np.std(ir, axis=0)\n",
    "std_err = std_dev / np.sqrt(ir.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean immediate regret at each evaluation averaged across all runs:\")\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Standard error of immediate regret at each evaluation averaged across all runs:\")\n",
    "print(std_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_dir + acquisition_name + \"_\" + objective_name + \"_\" + \"mean_sem\" + \".txt\", \"w\") as text_file:\n",
    "    print(\"Mean immediate regret at each evaluation averaged across all runs:\", file=text_file)\n",
    "    print(mean, file=text_file)\n",
    "    print(\"Standard error of immediate regret at each evaluation averaged across all runs:\", file=text_file)\n",
    "    print(std_err, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((mean, std_err), open(results_dir + acquisition_name + \"_\" + objective_name + \"_\" + \"mean_sem.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
