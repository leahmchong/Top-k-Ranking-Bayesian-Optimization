{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preferential Bayesian Optimization: Multinomial Predictive Entropy Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "print(tf.version.VERSION)\n",
    "\n",
    "from gpflow.utilities import set_trainable, print_summary\n",
    "gpflow.config.set_default_summary_fmt(\"notebook\")\n",
    "\n",
    "sys.path.append(os.path.split(os.path.split(os.path.split(os.getcwd())[0])[0])[0]) # Move 3 levels up directory to import project files as module\n",
    "import importlib\n",
    "PBO = importlib.import_module(\"Top-k-Ranking-Bayesian-Optimization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpu_to_use = 0\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_visible_devices(gpus[gpu_to_use], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Unique to real dataset ###\n",
    "\n",
    "features = pickle.load( open( \"sushi_features.p\", \"rb\" ) ) # Initial data x (100x6)\n",
    "#print(features.size)\n",
    "\n",
    "fvals = pickle.load( open( \"fvals.p\", \"rb\" ) ) # Inital data y (1x100)\n",
    "#print(fvals.size)\n",
    "\n",
    "# construct dict\n",
    "feat_to_fval_dict = {}\n",
    "for i in range(len(features)):\n",
    "    key = features[i].data.tobytes()\n",
    "    feat_to_fval_dict[key] = fvals[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = lambda x: PBO.objectives.sushi(x, feat_to_fval_dict)\n",
    "objective_low = np.min(features)\n",
    "objective_high = np.max(features)\n",
    "objective_name = \"SUSHI\"\n",
    "acquisition_name = \"MPES\"\n",
    "experiment_name = acquisition_name + \"_\" + objective_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 1 # number of experiments \n",
    "num_evals = 10 # number of queries\n",
    "num_choices = 2 # 2 if pairwise\n",
    "input_dims = 6\n",
    "num_maximizers = 20 # maximizer = x* that maximizes the objective function \n",
    "num_maximizers_init = 50\n",
    "num_fourier_features = 1000\n",
    "num_init_prefs = 10 # number of initial observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  /home/johnson/Top-k-Ranking-Bayesian-Optimization/experiments/SUSHI/results/MPES_SUSHI/  already exists\n"
     ]
    }
   ],
   "source": [
    "results_dir = os.getcwd() + '/results/' + experiment_name + '/'\n",
    "\n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.makedirs(results_dir)\n",
    "    print(\"Directory \" , results_dir ,  \" created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , results_dir ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noisy_observation(X, objective): # noisy (human) observations\n",
    "    f = PBO.objectives.objective_get_f_neg(X, objective)\n",
    "    return PBO.observation_model.gen_observation_from_f(X, f, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_visualize(X, y, title, lengthscale_init=None, signal_variance_init=None):\n",
    "    \n",
    "    # Train model with data\n",
    "    result = PBO.models.learning_fullgp.train_model_fullcov(\n",
    "                        X, y, \n",
    "                        obj_low=objective_low,\n",
    "                        obj_high=objective_high,\n",
    "                        lengthscale_init=lengthscale_init,\n",
    "                        signal_variance_init=signal_variance_init,\n",
    "                        indifference_threshold=0.,\n",
    "                        n_sample=1000, # number of samples to estimate the probabilities in Eq. 8\n",
    "                        deterministic=True, # only sample f values once, not re-sampling\n",
    "                        num_steps=500) # how many optimization steps to take when training model\n",
    "    \n",
    "    q_mu = result['q_mu']\n",
    "    q_sqrt = result['q_sqrt']\n",
    "    u = result['u']\n",
    "    inputs = result['inputs']\n",
    "    k = result['kernel']\n",
    "    \n",
    "    likelihood = gpflow.likelihoods.Gaussian()\n",
    "    model = PBO.models.learning.init_SVGP_fullcov(q_mu, q_sqrt, u, k, likelihood)\n",
    "    u_mean = q_mu.numpy()\n",
    "    inducing_vars = u.numpy()\n",
    "    \n",
    "    return model, inputs, u_mean, inducing_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate rank dictionary and immediate regret dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Unique to real dataset ###\n",
    "\n",
    "fval_idx_tuples = pickle.load(open(\"fval_idx_tuples.p\", \"rb\"))\n",
    "\n",
    "rank_dict = {}\n",
    "\n",
    "for i in range(len(fval_idx_tuples)):\n",
    "    rank_dict[features[fval_idx_tuples[i][1]].data.tobytes()] = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is our main metric for the performance of the acquisition function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_sushi(model, features, rank_dict):\n",
    "    \"\"\"\n",
    "    :param model: gpflow model\n",
    "    :param features: sushi features\n",
    "    :param rank_dict: dictionary from sushi idx to place in ranking\n",
    "    :return: tuple (index of max sushi, rank)\n",
    "    \"\"\"\n",
    "    f_preds = model.predict_f(features)[0]\n",
    "    max_idx = np.argmax(f_preds)\n",
    "    \n",
    "    return (max_idx, rank_dict[features[max_idx].data.tobytes()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the results in these arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_at_end = int(num_init_prefs + num_evals)\n",
    "X_results = np.zeros([num_runs, num_data_at_end, num_choices, input_dims])\n",
    "y_results = np.zeros([num_runs, num_data_at_end, 1, input_dims])\n",
    "immediate_regret = np.zeros([num_runs, num_evals], np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the initial values for each run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "### Unique for real dataset ###\n",
    "random_indices = np.random.choice(features.shape[0], [num_runs, num_init_prefs, num_choices])\n",
    "init_vals = np.take(features, random_indices, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loops carry out the Bayesian optimization algorithm over a number of runs, with a fixed number of evaluations per run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning run 0\n",
      "Optimizer config:  {'name': 'RMSprop', 'learning_rate': 0.001, 'decay': 0.0, 'rho': 0.0, 'momentum': 0.0, 'epsilon': 1e-07, 'centered': False}\n",
      "Indifference_threshold is fixed at 0.0\n",
      "Initialize lengthscale at [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "       signal variance at 1.0\n",
      "   Initial negative ELBO: 253.74041660531336\n",
      "Negative ELBO at step 0: 251.5538582428323 in 0.6443s\n",
      "Beginning evaluation 0\n",
      "Evaluation 0: Sampling maximizers\n",
      "Loss at step 0: -0.01831601459009835\n",
      "Loss at step 500: -1.0622422575873083\n",
      "Loss at step 1000: -1.33090823801621\n",
      "Loss at step 1500: -1.3592598285443793\n",
      "Loss at step 1695: -1.3598156381420585\n",
      "test.shape =  (20, 50, 1)\n",
      "tf.Tensor(\n",
      "[[1.         0.00291997 0.57294442 0.35458208 0.40934695 0.59125691]\n",
      " [1.         0.         0.4393938  0.64922429 0.28895994 0.29204521]\n",
      " [0.96644831 0.         0.38832884 0.85110676 0.24258977 0.89259462]\n",
      " [0.90413062 0.         0.32121315 0.77562711 0.20299442 0.84045345]\n",
      " [0.97340432 0.         0.75644195 0.41654393 0.23086531 0.50707334]\n",
      " [1.         0.         0.77858028 0.39869582 0.38615682 0.08302577]\n",
      " [1.         0.         0.65643165 0.18994566 0.0267447  0.        ]\n",
      " [0.94341093 0.         0.96690788 0.17425153 0.43940142 0.06307267]\n",
      " [0.89746048 0.01248975 0.73134163 0.63290151 0.30596499 0.22545639]\n",
      " [1.         0.         0.81822422 0.40232636 0.08277112 0.24584961]\n",
      " [0.99141182 0.00663898 0.66973867 0.62145696 0.52983538 0.07026892]\n",
      " [1.         0.         0.69055124 0.55770957 0.87282626 0.22941041]\n",
      " [0.94817953 0.01365908 0.71121557 0.63008798 0.87467275 0.14621541]\n",
      " [0.91475278 0.         0.48729993 0.56310441 0.2576914  0.        ]\n",
      " [0.91882374 0.00249451 0.68018347 0.45399359 0.17237914 0.77569055]\n",
      " [1.         1.         0.77819093 0.17403295 0.         0.04014322]\n",
      " [0.91250875 0.         0.36266739 0.73047384 0.26164926 0.76197694]\n",
      " [0.04950594 0.         0.69966288 0.25324899 0.26228732 0.        ]\n",
      " [0.97328727 0.01468486 0.61306986 0.53966103 0.26692415 0.71985883]\n",
      " [1.         0.         0.80599158 0.15902242 0.44726853 0.20776092]], shape=(20, 6), dtype=float64)\n",
      "Evaluation 0: Calculating I\n",
      "Evaluation 0: Next query is tf.Tensor(\n",
      "[[1.         0.         0.78225806 0.24946237 0.38254217 0.08      ]\n",
      " [1.         0.         0.60620915 0.5620915  0.63119457 0.08      ]], shape=(2, 6), dtype=float64) with I value of 0.06428746002067899\n",
      "Evaluation 0: Training model\n",
      "Optimizer config:  {'name': 'RMSprop', 'learning_rate': 0.001, 'decay': 0.0, 'rho': 0.0, 'momentum': 0.0, 'epsilon': 1e-07, 'centered': False}\n",
      "Indifference_threshold is fixed at 0.0\n",
      "Initialize lengthscale at [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "       signal variance at 1.0\n",
      "   Initial negative ELBO: 311.59922193812497\n",
      "Negative ELBO at step 0: 308.81062039892856 in 0.0771s\n",
      "Maximizing sushi has index 22 and rank 10\n",
      "Beginning evaluation 1\n",
      "Evaluation 1: Sampling maximizers\n",
      "Loss at step 0: -0.02349476299704895\n",
      "Loss at step 500: -1.2935894123672345\n",
      "Loss at step 1000: -1.6279274974278892\n",
      "Loss at step 1500: -1.6609621412721984\n",
      "Loss at step 2000: -1.6632127346097596\n",
      "Loss at step 2015: -1.6632157554124627\n",
      "test.shape =  (20, 50, 1)\n",
      "tf.Tensor(\n",
      "[[0.93917672 0.03677693 0.64770362 0.73459816 0.41800966 0.10184657]\n",
      " [0.91597082 0.03123876 0.68557256 0.48084042 0.23494114 0.71445559]\n",
      " [1.         0.         0.5234178  0.60993518 0.10077428 0.80572491]\n",
      " [0.96298337 0.         0.86033755 0.31280709 0.17260631 0.38614823]\n",
      " [0.99716584 0.         0.59443606 0.62006768 0.68651036 0.        ]\n",
      " [1.         0.         0.69625468 0.5805495  0.82960188 0.11708223]\n",
      " [0.99771335 0.         0.76704692 0.37201198 0.89886535 0.25798556]\n",
      " [0.94422925 0.01167387 0.80408573 0.20294705 0.29263883 0.30672604]\n",
      " [0.87353043 0.         0.81150785 0.45060282 0.24252747 0.32372952]\n",
      " [0.99925237 0.         0.5805842  0.63174096 0.55435536 0.        ]\n",
      " [1.         0.         0.45456312 0.72723353 0.27746023 0.87093791]\n",
      " [0.83707664 0.03182854 0.60321722 0.27433493 0.28281806 0.47080194]\n",
      " [0.98445078 0.00101116 0.82404033 0.43238846 0.91993249 0.25490388]\n",
      " [1.         0.03191226 0.9142016  0.40158973 0.11663691 0.32799733]\n",
      " [1.         0.         0.77028463 0.5610424  0.88569436 0.25128113]\n",
      " [1.         0.03142626 0.74713627 0.20782045 0.42499296 0.34146438]\n",
      " [0.96060204 0.         0.63254742 0.48165635 0.75208821 0.25805382]\n",
      " [1.         0.         0.86754942 0.28261864 0.17587475 0.3142861 ]\n",
      " [0.93823952 0.         0.64933437 0.54519324 0.28042346 0.54861255]\n",
      " [0.99893026 0.00292469 0.45741872 0.73544546 0.23089056 0.79652081]], shape=(20, 6), dtype=float64)\n",
      "Evaluation 1: Calculating I\n",
      "Evaluation 1: Next query is tf.Tensor(\n",
      "[[1.         0.         0.60620915 0.5620915  0.63119457 0.08      ]\n",
      " [1.         0.         0.6429626  0.33103675 0.24575436 0.6       ]], shape=(2, 6), dtype=float64) with I value of 0.07546130222723088\n",
      "Evaluation 1: Training model\n",
      "Optimizer config:  {'name': 'RMSprop', 'learning_rate': 0.001, 'decay': 0.0, 'rho': 0.0, 'momentum': 0.0, 'epsilon': 1e-07, 'centered': False}\n",
      "Indifference_threshold is fixed at 0.0\n",
      "Initialize lengthscale at [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "       signal variance at 1.0\n",
      "   Initial negative ELBO: 446.34524072281465\n",
      "Negative ELBO at step 0: 441.7238349516998 in 0.0693s\n",
      "Maximizing sushi has index 79 and rank 9\n",
      "Beginning evaluation 2\n",
      "Evaluation 2: Sampling maximizers\n",
      "Loss at step 0: -0.01193549200494674\n",
      "Loss at step 500: -1.254010069393495\n",
      "Loss at step 1000: -1.5604481235696313\n",
      "Loss at step 1500: -1.597532190101435\n",
      "Loss at step 2000: -1.5996043550631187\n",
      "Loss at step 2070: -1.5996257415866877\n",
      "test.shape =  (20, 50, 1)\n",
      "tf.Tensor(\n",
      "[[1.         0.         0.46635752 0.6109539  0.35472974 0.2221122 ]\n",
      " [0.18223462 0.00749331 0.36600547 0.30390076 0.0999514  0.13346423]\n",
      " [0.96195012 0.04017711 0.65379142 0.67366056 0.47489763 0.54129441]\n",
      " [0.97388065 0.         0.39465279 0.77704684 0.19133871 0.87565282]\n",
      " [0.95511577 0.         0.70558462 0.53698948 0.94830412 0.22710696]\n",
      " [1.         0.01755908 0.4766962  0.5547632  0.24406342 0.14297324]\n",
      " [0.9730901  0.98029994 0.37680991 0.11921027 0.50055705 0.13902087]\n",
      " [1.         0.01419989 0.39491614 0.58053477 0.1962435  0.29760167]\n",
      " [0.98390644 0.03596563 0.84586493 0.08799579 0.56857298 0.0303222 ]\n",
      " [0.99360021 0.         0.68106226 0.2272007  0.58078733 0.5080167 ]\n",
      " [1.         0.         0.41385898 0.34407097 0.38031371 0.        ]\n",
      " [0.97428466 0.01109893 0.68575849 0.69190751 0.77022866 0.12082   ]\n",
      " [0.86772167 0.03453443 0.45753761 0.62881171 0.23888324 0.52861478]\n",
      " [0.98716797 0.         0.93302885 0.483691   0.19644229 0.34770004]\n",
      " [1.         0.02262142 0.7172802  0.68414072 0.38933864 0.3494124 ]\n",
      " [1.         0.         0.55312457 0.14010492 0.71657687 0.11058021]\n",
      " [0.94352696 0.02846342 0.89623996 0.29171645 0.5949984  0.22035023]\n",
      " [0.95862411 0.00590929 0.65420016 0.68234408 0.27649202 0.37597609]\n",
      " [1.         0.03155493 0.63312303 0.65683403 0.23688569 0.12769461]\n",
      " [0.96536593 0.02081672 0.82906159 0.46133234 0.2287153  0.16909096]], shape=(20, 6), dtype=float64)\n",
      "Evaluation 2: Calculating I\n",
      "Evaluation 2: Next query is tf.Tensor(\n",
      "[[1.         0.         0.60620915 0.5620915  0.63119457 0.08      ]\n",
      " [1.         0.         0.49253731 0.14427861 0.57381325 0.04      ]], shape=(2, 6), dtype=float64) with I value of 0.06007697969034549\n",
      "Evaluation 2: Training model\n",
      "Optimizer config:  {'name': 'RMSprop', 'learning_rate': 0.001, 'decay': 0.0, 'rho': 0.0, 'momentum': 0.0, 'epsilon': 1e-07, 'centered': False}\n",
      "Indifference_threshold is fixed at 0.0\n",
      "Initialize lengthscale at [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "       signal variance at 1.0\n",
      "   Initial negative ELBO: 558.7653389659905\n",
      "Negative ELBO at step 0: 553.0069986293823 in 0.0826s\n",
      "Maximizing sushi has index 9 and rank 6\n",
      "Beginning evaluation 3\n",
      "Evaluation 3: Sampling maximizers\n",
      "Loss at step 0: 0.06680332473847189\n",
      "Loss at step 500: -1.1996523515999518\n",
      "Loss at step 1000: -1.4652678569294837\n",
      "Loss at step 1500: -1.5027216064472244\n",
      "Loss at step 2000: -1.5083985934755193\n",
      "Loss at step 2034: -1.5084170700865325\n",
      "test.shape =  (20, 50, 1)\n",
      "tf.Tensor(\n",
      "[[0.99558176 0.         0.69007985 0.51347416 0.96320447 0.24716363]\n",
      " [0.96546812 0.         0.828646   0.67956998 0.26893069 0.14997474]\n",
      " [1.         0.         0.53756816 0.65698032 0.31000296 0.37800114]\n",
      " [0.95502211 0.0277314  0.55009128 0.11200012 0.55206984 0.        ]\n",
      " [1.         1.         0.74903735 0.15609854 0.         0.01109089]\n",
      " [1.         0.01745621 0.71971395 0.2926433  0.87618478 0.23194776]\n",
      " [0.96965785 0.         0.71374225 0.07536455 0.50149408 0.01818006]\n",
      " [1.         0.007983   0.90566617 0.50654301 0.32202087 0.22339264]\n",
      " [0.94962187 0.         0.62313107 0.48786046 0.71959284 0.946008  ]\n",
      " [0.94327416 0.         0.74555223 0.61409999 0.30085779 0.37471665]\n",
      " [1.         0.00149481 0.74386022 0.67637058 0.34363694 0.61782436]\n",
      " [0.99720206 1.         0.79175323 0.14311578 0.         0.01727157]\n",
      " [1.         0.         0.45954346 0.78017763 0.25543562 0.82712884]\n",
      " [0.75536955 0.09014648 0.85499321 0.46334557 0.31688323 0.        ]\n",
      " [1.         1.         0.83378321 0.16730821 0.         0.02849278]\n",
      " [0.9445879  0.00631196 0.62434903 0.69535864 0.26888281 0.63795441]\n",
      " [1.         0.00867759 0.82712627 0.34340425 0.06427057 0.23571385]\n",
      " [1.         1.         0.79778549 0.18405849 0.         0.02033677]\n",
      " [1.         0.         0.87692715 0.34528266 0.79965349 0.254178  ]\n",
      " [1.         0.         0.61870061 0.57984726 0.23056023 0.20351989]], shape=(20, 6), dtype=float64)\n",
      "Evaluation 3: Calculating I\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation 3: Next query is tf.Tensor(\n",
      "[[1.         0.         0.49253731 0.14427861 0.57381325 0.04      ]\n",
      " [1.         0.         0.7706422  0.48929664 0.09563554 0.12      ]], shape=(2, 6), dtype=float64) with I value of 0.04859596125835299\n",
      "Evaluation 3: Training model\n",
      "Optimizer config:  {'name': 'RMSprop', 'learning_rate': 0.001, 'decay': 0.0, 'rho': 0.0, 'momentum': 0.0, 'epsilon': 1e-07, 'centered': False}\n",
      "Indifference_threshold is fixed at 0.0\n",
      "Initialize lengthscale at [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "       signal variance at 1.0\n",
      "   Initial negative ELBO: 646.3615518140523\n",
      "Negative ELBO at step 0: 639.6848505922098 in 0.0811s\n",
      "Maximizing sushi has index 57 and rank 27\n",
      "Beginning evaluation 4\n",
      "Evaluation 4: Sampling maximizers\n",
      "Loss at step 0: 0.03529469227055927\n",
      "Loss at step 500: -1.1396583801009406\n",
      "Loss at step 1000: -1.4106328440394005\n",
      "Loss at step 1500: -1.4405618346977085\n",
      "Loss at step 2000: -1.4431345703995129\n",
      "Loss at step 2467: -1.4445387525904974\n",
      "test.shape =  (20, 50, 1)\n",
      "tf.Tensor(\n",
      "[[1.         0.         0.60539646 0.46698927 0.33291945 0.        ]\n",
      " [0.98774888 0.00206104 0.44137932 0.05997533 0.66086284 0.06711423]\n",
      " [0.97481383 0.02338114 0.99238566 0.03064231 0.30757444 0.        ]\n",
      " [1.         0.         0.80462741 0.48468673 0.02700405 0.        ]\n",
      " [1.         0.         0.44365021 0.43646787 0.15478608 0.20685678]\n",
      " [1.         0.         0.69251722 0.67526072 0.51857988 0.        ]\n",
      " [0.66746477 0.00413801 0.82428555 0.1572565  0.20693292 0.20237226]\n",
      " [0.96854653 0.         0.70480759 0.63798408 0.92122341 0.20712596]\n",
      " [0.87688029 0.         0.77462345 0.66212668 0.26470421 0.16879096]\n",
      " [1.         0.         0.6137778  0.35390536 0.91004239 0.24773655]\n",
      " [0.91408191 0.         0.65254122 0.55355672 0.3390995  0.28268667]\n",
      " [1.         0.         0.78806492 0.64905423 0.23912307 0.16329642]\n",
      " [0.62932287 0.         0.48759401 0.48196373 0.03949159 0.15223405]\n",
      " [0.         0.         0.6421829  0.34293718 0.2551126  0.11151234]\n",
      " [0.89096366 0.03530936 0.80220504 0.22771512 0.1024037  0.08033821]\n",
      " [0.97425737 0.0239079  0.76247516 0.61749381 0.16300379 0.18318726]\n",
      " [0.96607183 0.         0.75194687 0.45431387 0.8449399  0.44014909]\n",
      " [0.8623039  0.         0.60720917 0.72942456 0.48057252 0.13926779]\n",
      " [1.         0.         0.89037028 0.26919215 0.33007956 0.        ]\n",
      " [0.88115664 0.         0.47351495 0.71271191 0.43932083 0.09552476]], shape=(20, 6), dtype=float64)\n",
      "Evaluation 4: Calculating I\n",
      "Evaluation 4: Next query is tf.Tensor(\n",
      "[[1.         0.         0.67008197 0.43169399 0.69292297 0.2       ]\n",
      " [1.         0.         0.37152778 0.45833333 0.32276995 0.08      ]], shape=(2, 6), dtype=float64) with I value of 0.04980076875947012\n",
      "Evaluation 4: Training model\n",
      "Optimizer config:  {'name': 'RMSprop', 'learning_rate': 0.001, 'decay': 0.0, 'rho': 0.0, 'momentum': 0.0, 'epsilon': 1e-07, 'centered': False}\n",
      "Indifference_threshold is fixed at 0.0\n",
      "Initialize lengthscale at [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "       signal variance at 1.0\n",
      "   Initial negative ELBO: 678.9164383351554\n",
      "Negative ELBO at step 0: 671.9087199188347 in 0.0816s\n",
      "Maximizing sushi has index 57 and rank 27\n",
      "Beginning evaluation 5\n",
      "Evaluation 5: Sampling maximizers\n",
      "Loss at step 0: 0.0031940274060594815\n",
      "Loss at step 500: -1.3640206257712113\n",
      "Loss at step 1000: -1.6986791373212635\n",
      "Loss at step 1500: -1.7411626497181523\n",
      "Loss at step 1902: -1.7429649492962749\n",
      "test.shape =  (20, 50, 1)\n",
      "tf.Tensor(\n",
      "[[0.92449409 0.         0.53272745 0.72493302 0.69917846 0.05948292]\n",
      " [0.68815759 0.         0.67112116 0.48102645 0.47817871 0.07200304]\n",
      " [0.958493   0.         0.76695535 0.11965673 0.06684507 0.17448579]\n",
      " [1.         0.         0.68930141 0.59610984 0.45665585 0.        ]\n",
      " [0.87937285 0.02038269 0.66279821 0.32438891 0.50526012 0.26817931]\n",
      " [1.         0.         0.70891713 0.63274116 0.79902212 0.09035353]\n",
      " [0.98983414 0.03855621 0.73505086 0.55287487 0.96670569 0.2079206 ]\n",
      " [0.         0.93133588 0.87252202 0.46517254 0.03157949 0.13876893]\n",
      " [1.         0.         0.33043986 0.55346802 0.34288629 0.        ]\n",
      " [1.         0.         0.59535699 0.60647166 0.50372437 0.        ]\n",
      " [1.         0.         0.31489804 0.62795926 0.36401602 0.        ]\n",
      " [1.         0.04392166 0.35480907 0.83483088 0.26236974 0.74124983]\n",
      " [0.95693196 0.         0.77182433 0.58674712 0.         0.14900731]\n",
      " [0.80697341 0.         0.94191807 0.33421086 0.33245578 0.        ]\n",
      " [1.         0.         0.68157494 0.6612716  0.70000324 0.        ]\n",
      " [1.         0.         0.69466131 0.75588015 0.         0.12239204]\n",
      " [0.94906628 0.         0.6115112  0.63058754 0.88518385 0.10154188]\n",
      " [1.         0.02366483 0.95452854 0.10661979 0.29758199 0.11627351]\n",
      " [0.96687389 0.02434481 0.56641825 0.69852987 0.2937638  0.49193283]\n",
      " [0.93893927 0.17980263 0.69759826 0.39428399 0.83716812 0.06132919]], shape=(20, 6), dtype=float64)\n",
      "Evaluation 5: Calculating I\n",
      "Evaluation 5: Next query is tf.Tensor(\n",
      "[[1.         0.         0.78225806 0.24946237 0.38254217 0.08      ]\n",
      " [1.         0.         0.60620915 0.5620915  0.63119457 0.08      ]], shape=(2, 6), dtype=float64) with I value of 0.05290581938120879\n",
      "Evaluation 5: Training model\n",
      "Optimizer config:  {'name': 'RMSprop', 'learning_rate': 0.001, 'decay': 0.0, 'rho': 0.0, 'momentum': 0.0, 'epsilon': 1e-07, 'centered': False}\n",
      "Indifference_threshold is fixed at 0.0\n",
      "Initialize lengthscale at [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "       signal variance at 1.0\n",
      "   Initial negative ELBO: 675.2476771846001\n",
      "Negative ELBO at step 0: 668.3512919018776 in 0.1096s\n",
      "Maximizing sushi has index 79 and rank 9\n",
      "Beginning evaluation 6\n",
      "Evaluation 6: Sampling maximizers\n",
      "Loss at step 0: 0.04836974296555424\n",
      "Loss at step 500: -1.3141370279231408\n",
      "Loss at step 1000: -1.5950797342320522\n",
      "Loss at step 1500: -1.6284066183173573\n",
      "Loss at step 2000: -1.6305688118371988\n",
      "Loss at step 2150: -1.6306804223498113\n",
      "test.shape =  (20, 50, 1)\n",
      "tf.Tensor(\n",
      "[[1.         1.         0.52152795 0.42943821 0.15325135 0.17349228]\n",
      " [1.         0.         0.70475161 0.61140853 0.92351533 0.20640881]\n",
      " [0.90601137 0.10056056 0.6812053  0.39773673 0.2761252  0.14793105]\n",
      " [1.         0.         0.69138009 0.76810602 0.2798191  0.18064643]\n",
      " [1.         0.         0.86045817 0.33412077 0.41104104 0.19496001]\n",
      " [0.54589066 0.         0.61904188 0.15251306 0.03760224 0.2278159 ]\n",
      " [1.         0.         0.65249754 0.71897512 0.70404241 0.0346299 ]\n",
      " [0.88242525 0.         0.59486642 0.54682512 0.25919259 0.34812523]\n",
      " [1.         0.         0.8853583  0.6806835  0.13571179 0.25307475]\n",
      " [1.         0.         0.72365881 0.52912984 0.4008216  0.        ]\n",
      " [1.         0.03021909 0.67532016 0.73420388 0.47634452 0.        ]\n",
      " [0.9870679  0.01276172 0.51082366 0.65532956 0.31816627 0.38742124]\n",
      " [0.89222374 0.12702183 0.47663528 0.68955955 0.11160049 0.23044588]\n",
      " [0.7295651  0.         0.7946468  0.34188283 0.34081798 0.18531897]\n",
      " [1.         0.01151081 0.67065037 0.33938149 0.41897746 0.32590471]\n",
      " [0.96746033 0.         0.68711847 0.18879706 0.         0.        ]\n",
      " [0.95666208 0.03009171 0.76738798 0.38676874 0.36438528 0.02409912]\n",
      " [0.6447069  0.         0.69971525 0.41751767 0.30598344 0.26402603]\n",
      " [1.         0.         0.84377627 0.69767123 0.02485024 0.        ]\n",
      " [1.         0.         0.52766969 0.84869262 0.27130508 0.77584603]], shape=(20, 6), dtype=float64)\n",
      "Evaluation 6: Calculating I\n",
      "Evaluation 6: Next query is tf.Tensor(\n",
      "[[1.         0.         0.60620915 0.5620915  0.63119457 0.08      ]\n",
      " [1.         0.         0.59763948 0.33333333 0.42438272 0.4       ]], shape=(2, 6), dtype=float64) with I value of 0.05110977628802474\n",
      "Evaluation 6: Training model\n",
      "Optimizer config:  {'name': 'RMSprop', 'learning_rate': 0.001, 'decay': 0.0, 'rho': 0.0, 'momentum': 0.0, 'epsilon': 1e-07, 'centered': False}\n",
      "Indifference_threshold is fixed at 0.0\n",
      "Initialize lengthscale at [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "       signal variance at 1.0\n",
      "   Initial negative ELBO: 863.7491321564919\n",
      "Negative ELBO at step 0: 855.0115840222279 in 0.1114s\n",
      "Maximizing sushi has index 79 and rank 9\n",
      "Beginning evaluation 7\n",
      "Evaluation 7: Sampling maximizers\n",
      "Loss at step 0: 0.03978533750059666\n",
      "Loss at step 500: -1.3385936402664265\n",
      "Loss at step 1000: -1.6371537515943582\n",
      "Loss at step 1500: -1.6681579284095032\n",
      "Loss at step 1956: -1.6717535575077938\n",
      "test.shape =  (20, 50, 1)\n",
      "tf.Tensor(\n",
      "[[0.9203996  0.         0.53241795 0.72987366 0.76867756 0.00541731]\n",
      " [1.         0.         0.36481666 0.77633887 0.41793114 0.20754311]\n",
      " [1.         0.         0.9324355  0.12776367 0.32685568 0.19747716]\n",
      " [0.95167329 0.03122286 0.72123107 0.69415573 0.35823114 0.33330086]\n",
      " [1.         0.         0.87800848 0.4648987  0.22583838 0.26032988]\n",
      " [0.9920005  0.         0.71248411 0.37347233 0.40429941 0.06173962]\n",
      " [1.         0.         0.91715158 0.37907999 0.5155136  0.        ]\n",
      " [1.         0.         0.7823292  0.55335692 0.94037014 0.23765498]\n",
      " [0.90519886 0.         0.99066997 0.16994711 0.35646935 0.08892941]\n",
      " [0.90494218 0.06443449 0.73197258 0.63676758 0.24615619 0.43737265]\n",
      " [1.         0.         0.53915731 0.72005997 0.31485398 0.94876558]\n",
      " [0.97230532 0.92442444 0.2788942  0.28016949 0.50045716 0.10150024]\n",
      " [0.98909563 0.07000621 0.67852628 0.63362402 0.88330987 0.23218351]\n",
      " [1.         0.         0.67529567 0.78714516 0.68158959 0.        ]\n",
      " [0.98803158 0.         0.30813557 0.54998502 0.43502473 0.00824614]\n",
      " [0.57424509 0.         0.43344084 0.49488905 0.12338892 0.23737507]\n",
      " [0.9625447  0.         0.86257205 0.40420037 0.81850848 0.25796635]\n",
      " [1.         0.03233826 0.72811031 0.58700732 0.33486608 0.04790181]\n",
      " [1.         0.         0.65122882 0.71424405 0.09968206 0.87134902]\n",
      " [0.910533   0.         0.72189138 0.69151897 0.10539645 0.29221174]], shape=(20, 6), dtype=float64)\n",
      "Evaluation 7: Calculating I\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation 7: Next query is tf.Tensor(\n",
      "[[1.         0.         0.78225806 0.24946237 0.38254217 0.08      ]\n",
      " [1.         0.         0.31390977 0.69172932 0.42259731 0.28      ]], shape=(2, 6), dtype=float64) with I value of 0.05555415474697835\n",
      "Evaluation 7: Training model\n",
      "Optimizer config:  {'name': 'RMSprop', 'learning_rate': 0.001, 'decay': 0.0, 'rho': 0.0, 'momentum': 0.0, 'epsilon': 1e-07, 'centered': False}\n",
      "Indifference_threshold is fixed at 0.0\n",
      "Initialize lengthscale at [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "       signal variance at 1.0\n",
      "   Initial negative ELBO: 1040.8386690044235\n",
      "Negative ELBO at step 0: 1029.5955949952775 in 0.0982s\n",
      "Maximizing sushi has index 79 and rank 9\n",
      "Beginning evaluation 8\n",
      "Evaluation 8: Sampling maximizers\n",
      "Loss at step 0: 0.06453786165471825\n",
      "Loss at step 500: -1.2103144158617962\n",
      "Loss at step 1000: -1.4945385388100183\n",
      "Loss at step 1500: -1.5316784081329007\n",
      "Loss at step 2000: -1.5350214843662202\n",
      "Loss at step 2500: -1.5363882036855643\n",
      "Loss at step 2845: -1.5366250406454216\n",
      "test.shape =  (20, 50, 1)\n",
      "tf.Tensor(\n",
      "[[1.         0.06698715 0.36194279 0.86369877 0.37685626 0.65950808]\n",
      " [1.         0.02303982 0.53737307 0.75494887 0.57294921 0.13163252]\n",
      " [1.         0.         0.49649323 0.40503801 0.37276287 0.        ]\n",
      " [1.         0.         1.         0.33430781 0.3455519  0.12060025]\n",
      " [1.         0.         0.15265579 0.75970592 0.55200725 0.56922287]\n",
      " [0.11752528 0.         0.5790312  0.42321363 0.2940903  0.        ]\n",
      " [0.98999    0.02846905 0.74225718 0.67891132 0.70850234 0.        ]\n",
      " [0.99822793 0.         0.42792139 0.78411295 0.2244706  0.75356991]\n",
      " [1.         0.         0.78418796 0.62101849 0.14851142 0.        ]\n",
      " [0.93352942 0.         0.42208374 0.76665826 0.31564825 0.35784942]\n",
      " [1.         0.02440025 0.24858014 0.8658262  0.41857075 0.26731265]\n",
      " [0.89286182 0.03000873 0.67373593 0.68978853 0.21570063 0.39206518]\n",
      " [1.         0.         0.66757287 0.51349536 0.84285116 0.35920238]\n",
      " [0.98097799 0.05342289 0.91331322 0.70356858 0.07570592 0.06410115]\n",
      " [0.91135668 0.02032672 0.57951347 0.57090518 0.54369309 0.7309502 ]\n",
      " [0.91826215 0.         0.61156127 0.66421059 0.47284934 0.24704029]\n",
      " [0.95833494 0.04478313 0.73782632 0.56724635 0.92492727 0.36968893]\n",
      " [1.         0.         0.83096124 0.05714123 0.08487607 0.21262299]\n",
      " [0.97113903 0.         0.35623782 0.09240746 0.73645291 0.        ]\n",
      " [1.         0.00690092 0.71801696 0.58318305 0.95352632 0.25501037]], shape=(20, 6), dtype=float64)\n",
      "Evaluation 8: Calculating I\n",
      "Evaluation 8: Next query is tf.Tensor(\n",
      "[[1.         0.         0.31390977 0.69172932 0.42259731 0.28      ]\n",
      " [1.         0.         0.6317446  0.36300959 0.75927013 0.64      ]], shape=(2, 6), dtype=float64) with I value of 0.04249010802092933\n",
      "Evaluation 8: Training model\n",
      "Optimizer config:  {'name': 'RMSprop', 'learning_rate': 0.001, 'decay': 0.0, 'rho': 0.0, 'momentum': 0.0, 'epsilon': 1e-07, 'centered': False}\n",
      "Indifference_threshold is fixed at 0.0\n",
      "Initialize lengthscale at [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "       signal variance at 1.0\n",
      "   Initial negative ELBO: 1123.1100709975844\n",
      "Negative ELBO at step 0: 1110.895003153433 in 0.1233s\n",
      "Maximizing sushi has index 79 and rank 9\n",
      "Beginning evaluation 9\n",
      "Evaluation 9: Sampling maximizers\n",
      "Loss at step 0: -0.004084519566435372\n",
      "Loss at step 500: -1.3904698257157055\n",
      "Loss at step 1000: -1.7348526285882166\n",
      "Loss at step 1500: -1.7739652694256718\n",
      "Loss at step 1835: -1.7758454120650007\n",
      "test.shape =  (20, 50, 1)\n",
      "tf.Tensor(\n",
      "[[1.00000000e+00 0.00000000e+00 7.17807122e-01 6.78930539e-01\n",
      "  4.08371043e-01 1.68115308e-01]\n",
      " [9.23086514e-02 9.21705075e-01 7.97097374e-01 3.45304759e-01\n",
      "  0.00000000e+00 4.05142113e-02]\n",
      " [1.00000000e+00 1.00000000e+00 7.83934924e-01 1.15004434e-01\n",
      "  4.99468927e-02 0.00000000e+00]\n",
      " [1.00000000e+00 9.38273903e-04 6.36745272e-01 7.21246525e-01\n",
      "  7.93343092e-01 1.55234719e-01]\n",
      " [1.00000000e+00 0.00000000e+00 4.85952912e-01 6.80170012e-01\n",
      "  2.13335689e-01 5.33255871e-01]\n",
      " [1.00000000e+00 0.00000000e+00 8.62763323e-01 6.63048752e-01\n",
      "  9.14483894e-02 1.23302562e-01]\n",
      " [9.65252688e-01 1.87460739e-02 6.28801405e-01 1.27804027e-02\n",
      "  8.83522354e-01 5.83340834e-01]\n",
      " [9.93905819e-01 2.20918951e-02 7.31216148e-01 2.51312070e-01\n",
      "  9.11683293e-01 3.83176878e-01]\n",
      " [1.00000000e+00 0.00000000e+00 6.52045628e-01 6.90574831e-01\n",
      "  6.80313416e-01 4.97143010e-01]\n",
      " [1.12860716e-03 0.00000000e+00 6.06528128e-01 3.15970161e-01\n",
      "  1.37540029e-01 1.56581889e-02]\n",
      " [9.84289523e-01 0.00000000e+00 5.36169668e-01 3.99551233e-01\n",
      "  3.13230733e-01 7.63815730e-01]\n",
      " [1.00000000e+00 0.00000000e+00 1.00000000e+00 1.19481465e-01\n",
      "  3.35586034e-01 2.57800122e-01]\n",
      " [9.83403472e-01 0.00000000e+00 8.27396410e-01 6.24988370e-01\n",
      "  6.83525436e-02 2.94491342e-01]\n",
      " [1.00000000e+00 0.00000000e+00 7.81924858e-01 5.03110980e-01\n",
      "  3.93436274e-01 0.00000000e+00]\n",
      " [1.00000000e+00 2.18161260e-02 1.00000000e+00 4.04456327e-03\n",
      "  3.84636003e-01 5.77518361e-02]\n",
      " [9.60236868e-01 0.00000000e+00 7.42627038e-01 6.13731589e-01\n",
      "  2.81758231e-02 3.45152064e-02]\n",
      " [1.00000000e+00 4.42803181e-02 7.21699786e-01 6.92629117e-01\n",
      "  3.07065107e-01 4.82289222e-01]\n",
      " [1.00000000e+00 0.00000000e+00 4.62817622e-01 7.33784821e-01\n",
      "  4.36431949e-01 9.33665903e-01]\n",
      " [1.00000000e+00 3.26040871e-02 4.31807996e-01 7.19471733e-01\n",
      "  3.29399056e-01 8.65641381e-01]\n",
      " [1.00000000e+00 8.23035986e-02 6.57466198e-01 3.44994196e-01\n",
      "  9.19684606e-01 3.14235118e-01]], shape=(20, 6), dtype=float64)\n",
      "Evaluation 9: Calculating I\n",
      "Evaluation 9: Next query is tf.Tensor(\n",
      "[[1.         0.         0.7706422  0.48929664 0.09563554 0.12      ]\n",
      " [1.         0.         0.44238976 0.78283547 0.25096426 0.88      ]], shape=(2, 6), dtype=float64) with I value of 0.040369705543267236\n",
      "Evaluation 9: Training model\n",
      "Optimizer config:  {'name': 'RMSprop', 'learning_rate': 0.001, 'decay': 0.0, 'rho': 0.0, 'momentum': 0.0, 'epsilon': 1e-07, 'centered': False}\n",
      "Indifference_threshold is fixed at 0.0\n",
      "Initialize lengthscale at [0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "       signal variance at 1.0\n",
      "   Initial negative ELBO: 1292.8051085592554\n",
      "Negative ELBO at step 0: 1278.4088340976682 in 0.0760s\n",
      "Maximizing sushi has index 79 and rank 9\n",
      "Run 0 immediate regret: \n",
      "[ 9  8  5 26 26  8  8  8  8  8]\n"
     ]
    }
   ],
   "source": [
    "for run in range(num_runs):  # CHECK IF STARTING RUN IS CORRECT\n",
    "    print(\"Beginning run %s\" % (run))\n",
    "    \n",
    "    X = init_vals[run]\n",
    "    y = get_noisy_observation(X, objective)\n",
    "    \n",
    "    model, inputs, u_mean, inducing_vars = train_and_visualize(X, y, \"Run_{}:_Initial_model\".format(run))\n",
    "\n",
    "    for evaluation in range(num_evals):\n",
    "        print(\"Beginning evaluation %s\" % (evaluation)) \n",
    "        \n",
    "        success = False\n",
    "        fail_count = 0\n",
    "        while not success:\n",
    "            # TODO: THIS ONLY WORKS FOR TOP-1 OF 2, CHANGE TO APPROPRIATE QUERY SAMPLING FOR HIGHER NUMBER OF CHOICES\n",
    "            samples = PBO.models.learning_fullgp.construct_input_pairs(inputs, features)\n",
    "\n",
    "            # Sample maximizers\n",
    "            print(\"Evaluation %s: Sampling maximizers\" % (evaluation))\n",
    "            maximizers = PBO.fourier_features.sample_maximizers(X=inducing_vars,\n",
    "                                                                count=num_maximizers,\n",
    "                                                                n_init=num_maximizers_init,\n",
    "                                                                D=num_fourier_features,\n",
    "                                                                model=model,\n",
    "                                                                min_val=objective_low,\n",
    "                                                                max_val=objective_high,\n",
    "                                                                num_steps=500) # Added by Leah Chong\n",
    "            print(maximizers)\n",
    "\n",
    "            # Calculate PES value I for each possible next query\n",
    "            print(\"Evaluation %s: Calculating I\" % (evaluation))\n",
    "            I_vals = PBO.acquisitions.pes.I_batch(samples, maximizers, model)\n",
    "\n",
    "            # Select query that maximizes I\n",
    "            next_idx = np.argmax(I_vals)\n",
    "            next_query = samples[next_idx]\n",
    "            print(\"Evaluation %s: Next query is %s with I value of %s\" % (evaluation, next_query, I_vals[next_idx]))\n",
    "\n",
    "            X_temp = np.concatenate([X, [next_query]])\n",
    "            # Evaluate objective function\n",
    "            y_temp = np.concatenate([y, get_noisy_observation(np.expand_dims(next_query, axis=0), objective)], axis=0)\n",
    "            \n",
    "            try:\n",
    "                print(\"Evaluation %s: Training model\" % (evaluation))\n",
    "                model, inputs, u_mean, inducing_vars = train_and_visualize(X_temp, y_temp,\n",
    "                                                                           \"Run_{}_Evaluation_{}\".format(run, evaluation))\n",
    "                success = True\n",
    "\n",
    "            except ValueError as err:\n",
    "                print(err)\n",
    "                print(\"Retrying sampling random inputs\")\n",
    "                fail_count += 1\n",
    "\n",
    "            if fail_count >= 3:\n",
    "                print(\"Retry limit exceeded\")\n",
    "                raise ValueError(\"Failed\")\n",
    "                \n",
    "        \n",
    "        X = X_temp\n",
    "        y = y_temp\n",
    "        \n",
    "        # Save model\n",
    "        pickle.dump((X, y, inputs, \n",
    "                     model.kernel.variance, \n",
    "                     model.kernel.lengthscale, \n",
    "                     model.likelihood.variance, \n",
    "                     inducing_vars, \n",
    "                     model.q_mu, \n",
    "                     model.q_sqrt, \n",
    "                     maximizers), \n",
    "                    open(results_dir + \"Model_Run_{}_Evaluation_{}.p\".format(run, evaluation), \"wb\"))\n",
    "\n",
    "        (max_idx, rank) = get_max_sushi(model, features, rank_dict)\n",
    "        immediate_regret[run, evaluation] = rank - 1\n",
    "        \n",
    "        print(\"Maximizing sushi has index {} and rank {}\".format(max_idx, rank)) \n",
    "\n",
    "    X_results[run] = X\n",
    "    y_results[run] = y\n",
    "    print(\"Run {} immediate regret: \".format(run))\n",
    "    print(immediate_regret[run])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((X_results, y_results, immediate_regret), open(results_dir + \"res.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = immediate_regret \n",
    "mean = np.mean(ir, axis=0)\n",
    "std_dev = np.std(ir, axis=0)\n",
    "std_err = std_dev / np.sqrt(ir.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean immediate regret at each evaluation averaged across all runs:\n",
      "[ 9.  8.  5. 26. 26.  8.  8.  8.  8.  8.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean immediate regret at each evaluation averaged across all runs:\")\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard error of immediate regret at each evaluation averaged across all runs:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Standard error of immediate regret at each evaluation averaged across all runs:\")\n",
    "print(std_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_dir + acquisition_name + \"_\" + objective_name + \"_\" + \"mean_sem\" + \".txt\", \"w\") as text_file:\n",
    "    print(\"Mean immediate regret at each evaluation averaged across all runs:\", file=text_file)\n",
    "    print(mean, file=text_file)\n",
    "    print(\"Standard error of immediate regret at each evaluation averaged across all runs:\", file=text_file)\n",
    "    print(std_err, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((mean, std_err), open(results_dir + acquisition_name + \"_\" + objective_name + \"_\" + \"mean_sem.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topkrankbo",
   "language": "python",
   "name": "topkrankbo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
