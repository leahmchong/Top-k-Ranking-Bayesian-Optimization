{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preferential Bayesian Optimization: Multinomial Predictive Entropy Search\n",
    "This notebook demonstrates the use of the Multinomial Predictive Entropy Search (PES) acquisition function on ordinal (preference) data.\n",
    "\n",
    "Over the CIFAR-10 dataset, we define an arbitrary preference as such (with class number in parentheses):\n",
    "\n",
    "Airplane (0) > Automobile (1) > Ship (8) > Truck (9) > Bird (2) > Cat (3) > Deer (4) > Dog (5) > Frog (6) > Horse (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from gpflow.utilities import set_trainable, print_summary\n",
    "gpflow.config.set_default_summary_fmt(\"notebook\")\n",
    "\n",
    "sys.path.append(os.path.split(os.path.split(os.path.split(os.getcwd())[0])[0])[0]) # Move 3 levels up directory to import PBO\n",
    "import PBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_to_use = 4\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Restrict TensorFlow to only use the first GPU\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_visible_devices(gpus[gpu_to_use], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "    except RuntimeError as e:\n",
    "        # Visible devices must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cifar_embedding = pickle.load( open( \"cifar_embedding_reduced.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_to_class = pickle.load( open( \"embedding_to_class_reduced.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = lambda x: PBO.objectives.cifar(x, embedding_to_class)\n",
    "objective_low = np.min(cifar_embedding)\n",
    "objective_high = np.max(cifar_embedding)\n",
    "objective_name = \"CIFAR\"\n",
    "acquisition_name = \"MPES\"\n",
    "experiment_name = acquisition_name + \"_\" + objective_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 5\n",
    "num_evals = 35\n",
    "num_samples = 100\n",
    "num_choices = 2\n",
    "input_dims = 2\n",
    "objective_dim = input_dims # CHANGE 1: require the objective dim\n",
    "num_maximizers = 20\n",
    "num_maximizers_init = 50\n",
    "num_fourier_features = 1000\n",
    "num_init_prefs = 6 # CHANGE 2: randomly initialize with some preferences\n",
    "num_discrete_per_dim = 1000  # for plotting\n",
    "indiff = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = os.getcwd() + '/results/' + experiment_name + '/'\n",
    "\n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.makedirs(results_dir)\n",
    "    print(\"Directory \" , results_dir ,  \" created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , results_dir ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_class(x):\n",
    "    \"\"\"\n",
    "    :param x: tensor of shape (..., 2). CIFAR-10 embeddings\n",
    "    :return: tensor of shape (..., 1). last dim is int from 0-9 representing class\n",
    "    \"\"\"\n",
    "    shape = x.shape[:-1]\n",
    "    raveled = np.reshape(x, [-1, 2])\n",
    "    raveled_shape = raveled.shape[:-1]\n",
    "    raveled_classes = np.zeros((raveled_shape[0], 1), dtype=np.int8)\n",
    "    \n",
    "    for i in range(raveled_shape[0]):\n",
    "        raveled_classes[i] = embedding_to_class[raveled[i].data.tobytes()]\n",
    "        \n",
    "    return np.reshape(raveled_classes, shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gp(model, inducing_points, inputs, title, cmap=\"Spectral\"):\n",
    "\n",
    "    side = np.linspace(objective_low, objective_high, num_discrete_per_dim)\n",
    "    combs = PBO.acquisitions.dts.combinations(np.expand_dims(side, axis=1))\n",
    "    predictions = model.predict_y(combs)\n",
    "    preds = tf.transpose(tf.reshape(predictions[0], [num_discrete_per_dim, num_discrete_per_dim]))\n",
    "    variances = tf.transpose(tf.reshape(predictions[1], [num_discrete_per_dim, num_discrete_per_dim]))\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle(title)\n",
    "    fig.set_size_inches(18.5, 6.88)\n",
    "    fig.set_dpi((200))\n",
    "\n",
    "    ax1.axis('equal')\n",
    "    im1 = ax1.imshow(preds, \n",
    "                     interpolation='nearest', \n",
    "                     extent=(objective_low, objective_high, objective_low, objective_high), \n",
    "                     origin='lower', \n",
    "                     cmap=cmap)\n",
    "    ax1.plot(inducing_points[:, 0], inducing_points[:, 1], 'kx', mew=2)\n",
    "    ax1.plot(inputs[:, 0], inputs[:, 1], 'ko', mew=2, color='w')\n",
    "    ax1.set_title(\"Mean\")\n",
    "    ax1.set_xlabel(\"x0\")\n",
    "    ax1.set_ylabel(\"x1\")\n",
    "    fig.colorbar(im1, ax=ax1)\n",
    "\n",
    "    ax2.axis('equal')\n",
    "    im2 = ax2.imshow(variances, \n",
    "                     interpolation='nearest', \n",
    "                     extent=(objective_low, objective_high, objective_low, objective_high), \n",
    "                     origin='lower', \n",
    "                     cmap=cmap)\n",
    "    ax2.plot(inducing_points[:, 0], inducing_points[:, 1], 'kx', mew=2)\n",
    "    ax2.plot(inputs[:, 0], inputs[:, 1], 'ko', mew=2, color='w')\n",
    "    ax2.set_title(\"Variance\")\n",
    "    ax2.set_xlabel(\"x0\")\n",
    "    ax2.set_ylabel(\"x1\")\n",
    "    fig.colorbar(im2, ax=ax2)\n",
    "\n",
    "    plt.savefig(fname=results_dir + title + \".png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noisy_observation(X, objective, indiff):\n",
    "    f = PBO.objectives.objective_get_f_neg(X, objective)\n",
    "    obs = PBO.observation_model.gen_observation_from_f(X, f, 1)\n",
    "    new_obs = []\n",
    "    for i in range(len(f)):\n",
    "        pair = f[i]\n",
    "        if abs(pair[0,0] - pair[1,0]) <= indiff:  # f-values are close enough such that no preference\n",
    "            choice = np.random.randint(0,2,1)[0]  # since top 1 of 2, randomly pick between first and second choices\n",
    "            new_obs.append(np.array([X[i, choice]]))  # replace our returned observation with the randomly selected one\n",
    "        else:\n",
    "            new_obs.append(obs[i])\n",
    "    return new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_visualize(X, y, title, lengthscale_init=None, signal_variance_init=None):\n",
    "    \n",
    "    # Train model with data\n",
    "    # CHANGE 6: use full_gp instead of sparse, \n",
    "    result = PBO.models.learning_fullgp.train_model_fullcov(\n",
    "                        X, y, \n",
    "                        obj_low=objective_low,\n",
    "                        obj_high=objective_high,\n",
    "                        lengthscale_init=lengthscale_init,\n",
    "                        signal_variance_init=signal_variance_init,\n",
    "                        indifference_threshold=0.,\n",
    "                        n_sample=1000,\n",
    "                        deterministic=True, # only sample f values once, not re-sampling\n",
    "                        num_steps=3000)\n",
    "    \n",
    "    q_mu = result['q_mu']\n",
    "    q_sqrt = result['q_sqrt']\n",
    "    u = result['u']\n",
    "    inputs = result['inputs']\n",
    "    k = result['kernel']\n",
    "    \n",
    "    likelihood = gpflow.likelihoods.Gaussian()\n",
    "    model = PBO.models.learning.init_SVGP_fullcov(q_mu, q_sqrt, u, k, likelihood)\n",
    "    u_mean = q_mu.numpy()\n",
    "    inducing_vars = u.numpy()\n",
    "    \n",
    "    # Visualize model\n",
    "    plot_gp(model, inducing_vars, inputs, title)\n",
    "    \n",
    "    return model, inputs, u_mean, inducing_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is our main metric for the performance of the acquisition function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pref_inversions(model):\n",
    "    \"\"\"\n",
    "    Method to evaluate models over discrete preference rankings. Given an objective preference ranking over classes, \n",
    "    we calculate the average mean the model assigns to each class, sort the classes according to this average mean,\n",
    "    then calculate the number of inversions required to reach the desired objective preference ranking. 0 inversions\n",
    "    means the model has learned the preference ranking perfectly. The more inversions, the further away the model is.\n",
    "    \"\"\"\n",
    "    def count_inversions(input_list):\n",
    "        def swap(lst, i, j):\n",
    "            tmp = lst[j]\n",
    "            lst[j] = lst[i]\n",
    "            lst[i] = tmp\n",
    "\n",
    "        lst = input_list.copy()\n",
    "        num_inversions = 0\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            for i in range(len(lst) - 1):\n",
    "                if lst[i] > lst[i+1]:\n",
    "                    swap(lst, i, i+1)\n",
    "                    num_inversions += 1\n",
    "                    changed = True\n",
    "                    \n",
    "        return num_inversions\n",
    "    \n",
    "    \n",
    "    class_to_posval = {0: -0.1,\n",
    "                     1: -0.2,\n",
    "                     8: -0.3,\n",
    "                     9: -0.4,\n",
    "                     2: -0.5,\n",
    "                     3: -0.6,\n",
    "                     4: -0.7,\n",
    "                     5: -0.8,\n",
    "                     6: -0.9,\n",
    "                     7: -1.}  # higher is more preferred here\n",
    "    \n",
    "    fvals = model.predict_f(cifar_embedding)[0]\n",
    "    indices = get_class(cifar_embedding)\n",
    "    \n",
    "    average_f = tf.scatter_nd(indices=indices,\n",
    "                   updates=np.squeeze(fvals),\n",
    "                   shape=tf.constant([10]))/5000\n",
    "    sorted_f = sorted(list(zip(average_f, range(10))))\n",
    "    \n",
    "    model_posvals = []\n",
    "    for pair in sorted_f:\n",
    "        model_posvals.append(class_to_posval[pair[1]])\n",
    "        \n",
    "    return count_inversions(model_posvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maximizing_class(model):\n",
    "    fvals = model.predict_f(cifar_embedding)[0]\n",
    "    indices = get_class(cifar_embedding)\n",
    "    \n",
    "    average_f = tf.scatter_nd(indices=indices,\n",
    "                   updates=np.squeeze(fvals),\n",
    "                   shape=tf.constant([10]))/5000\n",
    "    sorted_f = sorted(list(zip(average_f, range(10))))\n",
    "    return sorted_f[9][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the results in these arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_at_end = int(num_init_prefs + num_evals)\n",
    "X_results = np.zeros([num_runs, num_data_at_end, num_choices, input_dims])\n",
    "y_results = np.zeros([num_runs, num_data_at_end, 1, input_dims])\n",
    "inversion_results = np.zeros([num_runs, num_evals], np.int32)\n",
    "max_class_results = np.zeros([num_runs, num_evals], np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the initial values for each run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random_indices = np.random.choice(cifar_embedding.shape[0], [num_runs, num_init_prefs, num_choices])\n",
    "init_vals = np.take(cifar_embedding, random_indices, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following loops carry out the Bayesian optimization algorithm over a number of runs, with a fixed number of evaluations per run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in range(num_runs):  # CHECK IF STARTING RUN IS CORRECT\n",
    "    print(\"Beginning run %s\" % (run))\n",
    "    \n",
    "    X = init_vals[run]\n",
    "    y = get_noisy_observation(X, objective, indiff)\n",
    "    \n",
    "    model, inputs, u_mean, inducing_vars = train_and_visualize(X, y, \"Run_{}:_Initial_model\".format(run))\n",
    "\n",
    "    for evaluation in range(num_evals):\n",
    "        print(\"Beginning evaluation %s\" % (evaluation)) \n",
    "        \n",
    "        success = False\n",
    "        fail_count = 0\n",
    "        while not success:\n",
    "            # Sample possible next queries\n",
    "            samples = PBO.acquisitions.pes.sample_inputs_discrete(current_inputs=inputs,\n",
    "                                                                data=cifar_embedding,\n",
    "                                                                num_samples=num_samples,\n",
    "                                                                num_choices=num_choices)\n",
    "\n",
    "            # Sample maximizers\n",
    "            print(\"Evaluation %s: Sampling maximizers\" % (evaluation))\n",
    "            maximizers = PBO.fourier_features.sample_maximizers(X=inducing_vars,\n",
    "                                                                count=num_maximizers,\n",
    "                                                                n_init=num_maximizers_init,\n",
    "                                                                D=num_fourier_features,\n",
    "                                                                model=model,\n",
    "                                                                min_val=objective_low,\n",
    "                                                                max_val=objective_high)\n",
    "            print(maximizers)\n",
    "\n",
    "            # Calculate PES value I for each possible next query\n",
    "            print(\"Evaluation %s: Calculating I\" % (evaluation))\n",
    "            I_vals = PBO.acquisitions.pes.I_batch(samples, maximizers, model)\n",
    "\n",
    "            # Select query that maximizes I\n",
    "            next_idx = np.argmax(I_vals)\n",
    "            next_query = samples[next_idx]\n",
    "            print(\"Evaluation %s: Next query is %s with I value of %s\" % (evaluation, next_query, I_vals[next_idx]))\n",
    "\n",
    "            X_temp = np.concatenate([X, [next_query]])\n",
    "            # Evaluate objective function\n",
    "            y_temp = np.concatenate([y, get_noisy_observation(np.expand_dims(next_query, axis=0), objective, indiff)], axis=0)\n",
    "            \n",
    "            try:\n",
    "                print(\"Evaluation %s: Training model\" % (evaluation))\n",
    "                model, inputs, u_mean, inducing_vars = train_and_visualize(X_temp, y_temp,\n",
    "                                                                           \"Run_{}_Evaluation_{}\".format(run, evaluation))\n",
    "                success = True\n",
    "\n",
    "            except ValueError as err:\n",
    "                print(err)\n",
    "                print(\"Retrying sampling random inputs\")\n",
    "                fail_count += 1\n",
    "\n",
    "            if fail_count >= 10:\n",
    "                print(\"Retry limit exceeded\")\n",
    "                raise ValueError(\"Failed\")\n",
    "                \n",
    "        \n",
    "        X = X_temp\n",
    "        y = y_temp\n",
    "        \n",
    "        # Save model\n",
    "        pickle.dump((X, y, inputs, \n",
    "                     model.kernel.variance, \n",
    "                     model.kernel.lengthscale, \n",
    "                     model.likelihood.variance, \n",
    "                     inducing_vars, \n",
    "                     model.q_mu, \n",
    "                     model.q_sqrt, \n",
    "                     maximizers), \n",
    "                    open(results_dir + \"Model_Run_{}_Evaluation_{}.p\".format(run, evaluation), \"wb\"))\n",
    "\n",
    "        inversion_results[run, evaluation] = pref_inversions(model)\n",
    "        max_class_results[run, evaluation] = get_maximizing_class(model)\n",
    "        \n",
    "        print(\"Inversions: {}, maximizing class: {}\".format(inversion_results[run, evaluation], \n",
    "                                                           max_class_results[run, evaluation]))\n",
    "\n",
    "    X_results[run] = X\n",
    "    y_results[run] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((X_results, y_results, inversion_results, max_class_results), open(results_dir + \"PES_CIFAR_runs2-10.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_ir = {0:0, 1:1, 8:2, 9:3, 2:4, 3:5, 4:6, 5:7, 6:8, 7:9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = np.zeros(max_class_results.shape)\n",
    "for i in range(num_runs):\n",
    "    for j in range(num_evals):\n",
    "        ir[i, j] = max_class_results[i, j]\n",
    "        \n",
    "mean = np.mean(ir, axis=0)\n",
    "std_dev = np.std(ir, axis=0)\n",
    "std_err = std_dev / np.sqrt(ir.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean immediate regret at each evaluation averaged across all runs:\")\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Standard error of immediate regret at each evaluation averaged across all runs:\")\n",
    "print(std_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(results_dir + acquisition_name + \"_\" + objective_name + \"_\" + \"mean_sem\" + \".txt\", \"w\") as text_file:\n",
    "    print(\"Mean immediate regret at each evaluation averaged across all runs:\", file=text_file)\n",
    "    print(mean, file=text_file)\n",
    "    print(\"Standard error of immediate regret at each evaluation averaged across all runs:\", file=text_file)\n",
    "    print(std_err, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((mean, std_err), open(results_dir + acquisition_name + \"_\" + objective_name + \"_\" + \"mean_sem.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
